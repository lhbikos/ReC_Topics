
# waRming up {#waRmups}

[Screencasted Lecture Link](https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=fd132ba0-4bdc-47d4-94cd-ac40004a134b) 
 
```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
```

```{r include=FALSE}
options(scipen=999)#eliminates scientific notation
```

The beginning of any data analysis means familiarizing yourself with the data, that is, its distributional characteristics as well as its relations. 
 

## Navigating this Lesson

There is about 30 minutes of lecture.  

The R markdown file used to create this lecture as well as all of the figures are available at the [OER's GitHub site](https://github.com/lhbikos/ReC_Topics).

### Learning Objectives

Learning objectives from this lecture include the following:

* Produce descriptive statistics (means, standard deviations, skew, kurtosis), and correlation matrix, with the *psych* package
* Produce plots of data
* Interpret skew, kurtosis, correlations
* Create an APA Style table and results section that includes means, standard deviations, and correlations

### Planning for Practice

This is designed as a "get (back) into it" assignment.  You will essentially work through this very same lecture, using the same dataframe -- just a different set of continuous variables.

### Readings & Resources

In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.

* Revelle, W. (2020). An introduction to the psych package: Part I: data entry and data description.
  - Revelle is the author/creator of the *psych* package. His tutorial provides both technical and interpretive information. Read pages 1-17.
* Lui, P. P. (2020). Racial Microaggression, Overt Discrimination, and Distress: (In)Direct Associations With Psychological Adjustment. *The Counseling Psychologist, 32*.
  - We continue with the worked example from Lui; using simulated data for the lecture and homework assignment.
 
```{r  include=FALSE}
#will install the package if not already installed
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(psych)){install.packages("psych")}
if(!require(apaTables)){install.packages("apaTables")}
``` 

We will use simulated data from Lui [-@lui_racial_2020] for simple data screening. Controlling for overt discrimination and neuroticism, Lui examined the degree to which racial microaggression contributed to negative affect, alcohol consumption, and drinking problems in African American, Asian American, and Latinx American college students (*N* = 713).

Using the means, standard deviations, correlation matrix, and group sizes (*n*) I simulated the data. While the process of simulation is beyond the learning goals of this lesson (you can skip that part), I include it here so that it is easy to work the rest of the script.

```{r}
set.seed(210807)#sets the random seed so that we consistently get the same results
#for practice, you could change (or remove) the random seed and try to interpret the results (they should be quite similar)
#There are probe more efficient ways to simulate data.
#Given the information available in the manuscript, my approach was to first create the datasets for each of the racial ethnic groups that were provided and then binding them together.

#First, the data for the students who identified as Asian American
Asian_mu <- c(1.52, 1.72, 2.69, 1.71, 2.14, 2.35, 2.42)
Asian_stddev <- c(2.52, 2.04, 0.47, 0.70, 0.80, 2.41, 3.36)
Asian_corMat <- matrix(c(1.00,  0.69,  0.19,  0.28,  0.32,  0.08,  0.23,
                          0.69,  1.00,  0.20,  0.29,  0.33,  0.13,  0.25,
                          0.19,  0.20,  1.00,  0.50,  0.50, -0.04,  0.09,
                          0.28,  0.29,  0.50,  1.00,  0.76,  0.04,  0.18,
                          0.32,  0.33,  0.50,  0.76,  1.00,  0.10,  0.21,
                          0.08,  0.13, -0.04,  0.04,  0.10,  1.00,  0.42,
                          0.23,  0.25,  0.09,  0.18,  0.21,  0.42,  1.00),
                        ncol=7)
Asian_covMat <- Asian_stddev %*% t(Asian_stddev) * Asian_corMat

library(MASS)
Asian_dat <- mvrnorm(n = 398, mu = Asian_mu, Sigma = Asian_covMat, empirical = TRUE)
Asian_df <- as.data.frame(Asian_dat)

library(tidyverse)
Asian_df <- rename(Asian_df, OvDisc = V1, mAggr = V2, Neuro = V3, nAff = V4, psyDist = V5, Alcohol = V6, drProb = V7)
Asian_df$RacEth <- "Asian"

#Second, the data for the students who identified as Black/African American
Black_mu <- c(4.45, 3.84, 2.60, 1.84, 2.10, 2.81, 2.14)
Black_stddev <- c(4.22, 3.08, 0.89, 0.80, 0.81, 2.49, 3.24)
Black_corMat <- matrix(c( 1.00,  0.81,  0.17,  0.15,  0.09,  0.05, -0.16,
              0.81,  1.00,  0.17,  0.21,  0.11,  0.09, -0.01,
              0.17,  0.17,  1.00,  0.59,  0.54,  0.05,  0.24,
              0.15,  0.21,  0.59,  1.00,  0.72,  0.12,  0.22,
              0.09,  0.11,  0.54,  0.72,  1.00,  0.21,  0.40,
              0.05,  0.09,  0.05,  0.12,  0.21,  1.00,  0.65,
              -0.16,-0.01,  0.24,  0.22,  0.40,  0.65,  1.00),
           ncol = 7)
Black_covMat <- Black_stddev %*% t(Black_stddev) * Black_corMat
Black_dat <- mvrnorm(n = 133, mu = Black_mu, Sigma = Black_covMat, empirical = TRUE)
Black_df <- as.data.frame(Black_dat)
Black_df <- rename(Black_df, OvDisc = V1, mAggr = V2, Neuro = V3, nAff = V4, psyDist = V5, Alcohol = V6, drProb = V7)
Black_df$RacEth <- "Black"

#Third, the data for the students who identified as Latinx American
Latinx_mu <- c(1.56, 2.34, 2.69, 1.81, 2.17, 3.47, 2.69)
Latinx_stddev <- c(2.46, 2.49, 0.86, 0.71, 0.78, 2.59, 3.76)
Latinx_corMat <- matrix(c( 1.00,  0.78,  0.27,  0.36,  0.42, -0.06,  0.08,
                           0.78,  1.00,  0.33,  0.26,  0.35, -0.11, -0.02,
                           0.27,  0.33,  1.00,  0.62,  0.64, -0.04,  0.15,
                           0.36,  0.26,  0.62,  1.00,  0.81, -0.08,  0.17,
                           0.42,  0.35,  0.64,  0.81,  1.00, -0.06,  0.15,
                           -0.06,-0.11, -0.04, -0.08, -0.06,  1.00,  0.60,
                           0.08, -0.02,  0.15,  0.17,  0.15,  0.60,  1.00),
                        ncol = 7)
Latinx_covMat <- Latinx_stddev %*% t(Latinx_stddev) * Latinx_corMat
Latinx_dat <- mvrnorm(n = 182, mu = Latinx_mu, Sigma = Latinx_covMat, empirical = TRUE)
Latinx_df <- as.data.frame(Latinx_dat)
Latinx_df <- rename(Latinx_df, OvDisc = V1, mAggr = V2, Neuro = V3, nAff = V4, psyDist = V5, Alcohol = V6, drProb = V7)
Latinx_df$RacEth <- "Latinx"

Lui_sim_df <-bind_rows (Asian_df, Black_df, Latinx_df)
```
If you have simulated the data, you can continue using the the "Lui_sim_df" object that we created.  In your own research you may wish to save data as a file. Although I will hashtag it out (making it inoperable until the hashtags are removed), here is code to save the simulated data both .csv (think "Excel lite") and .rds (it retains all the properties we assigned to it in R) files and then bring/import them back into R.

```{r}
#write the simulated data  as a .csv
#write.table(Lui_sim_df, file="Lui_CSV.csv", sep=",", col.names=TRUE, row.names=FALSE)
#bring back the simulated dat from a .csv file
#df <- read.csv ("Lui_CSV.csv", header = TRUE)
```

```{r}
#to save the df as an .rds (think "R object") file on your computer; it should save in the same file as the .rmd file you are working with
#saveRDS(Lui_sim_df, "Lui_RDS.rds")
#bring back the simulated dat from an .rds file
#df <- readRDS("Lui_RDS.rds")
```

You may have noticed a couple of things in each of these operations

* First, I named the data object that global environment "df" (i.e., dataframe). 
  - It is a common (but not required) practice for researchers to simply use "df" or "dat" for their R script, no matter the type or source of the data. This practice has advantages (makes reusing code easy) and disadvantages (it's easy to get confused about what data is what).
* Second, if you run the code, the updating *replaces* the prior code. 
  - While this is irrelevant today (we are saving the same data in different ways), it points out the importance of creating a sensible and systematic *order of operations* in your .rmd files and then knowing where you are in the process.
  
Because the data is simulated, I can simply use the data I created in the simulation, however, I will go ahead and use the convention of renaming it, "df."

```{r}
df <- Lui_sim_df
```

Is this R session reading our variables correctly?  Check it with the "structure" command.

```{r}
str (df)
```

Looking back at the Lui [-@lui_racial_2020] article we can presume the following variables (variable/variable name) to have the following structure (scaling/R scaling):

* Discrimination/OvDis:interval/num
  - theoretically someone could experience no discrimination, but it would still score as 1.0 if the scale is averaged and the respondent marked 1 (never or not at all) for all the options.
* Microaggressions/mAggr: interval/num
 - theoretically someone could experience no microaggressions, but it would still score as 1.0 if the scale is averaged and the respondent marked 1 (never; and then not at all [stressful]) for all the options.
* Neuroticism/Neuro: interval/num
* Negative affect/nAff:interval/num
* Psychological distress/psyDist:interval/num
* Hazardous alcohol use/Alcohol:  interval/num
* Drinking problems/drProb:  interval/num
* Race Ethnicity/RacEth:  nominal/chr

Everything is fine except Race Ethnicity which needs to be a factor.  Let's change it and check again.

At this point I need to use the tidyverse package so that I can *mutate()* the RacEth variable to be a factor.

```{r }
# A .csv file is uninformed -- it just holds data (and R guesses what it is); respecifying the type of variable will likely need to be completed each time the file is used.

library(tidyverse)
df <- df %>%
    mutate(
        RacEth = as.factor(RacEth))
```

```{r }
#checking the structure of the data
str(df)
```

Manipulating the dat is an important skill. I can use the *select()* function to obtain  certain variable.  I want to select three variables that are continuous and then disaggregate them by race/ethnicity. 
```{r }
tiny_df <-(select (df, mAggr, nAff, psyDist))
```

We can start with simple descriptives. Revelle's [-@revelle_introduction_2020] *psych* package was made specifically for much of the type of work we do.

```{r }
library(psych)
describe(tiny_df)
```

One of the easiest way to get "counts" of categorical variables is to use them in the *psych* package's *describeBy()* function. In the script below, I am asking for descriptives of the entire df, but disaggregated by RacEth.
```{r}
describeBy (df, df$RacEth, mat=TRUE)
```

### Determining Skew and Kurtosis

To understand whether our data are normally distributed, we can look at skew and kurtosis.  The skew and kurtosis indices in the *psych* package are reported as *z* scores.  Regarding skew, values > 3.0 are generally considered "severely skewed."  Regarding kurtosis, "severely kurtotic" is argued anywhere > 8 to 20 [@kline_principles_2016].

### SPLOM 

SPLOM (scatterplot matrix) is a graphical tool that uses multiple scatterplots to deterine the correlation (if any) between a set of variables.  These plots are organized into a matrix, making it easy to see them all at once.

In the *psych* package, the *pairs.panels()* produces these. 

**On diagonal** we see:  

 * histogram of each variable
 * superimposed with a normal curve

**Below diagonal** we see: 

* xy scatter plot (not useful for our categorical RacEth row)
* the *lowess* locally fit regression line
* the X axis represents the column variable; the Y axis, the row variable

**Above diagonal** we see:

* Pearson correlation

```{r }
# the pch = "." command produces a cleaner graphic and is especially useful when there are lots of variables
pairs.panels(tiny_df, pch=".")
```

What do we observe?

* All 3 variables look normally distributed
* relationship between mAggr with nAff and psyDist is quite comparable
* relationship between nAff and psyDist is very strong
* are these correlations significant?  Revelle [-@revelle_introduction_2020] is not a fan of the associated *p* value, but we can get it several ways (hang tight).

Writing up an APA style results section usually involves some sort of table.  A super helpful package for doing this is *apaTables*.  Really cool is the instructional article (pubbed in a peer reviewed journal) that also talks about the contributions of tools like this contributing to the *reproducibility* of science by reducing errors and, if the R script/data are shared how the evaluation process is standardized and therefore reproducible [@stanley_reproducible_2018].

```{r }
library(apaTables)
```

```{r}
# unlike the psych package, this function removes any categorical variables
Table1_Cor <- apa.cor.table(tiny_df, filename = "Table1_Cor.doc", table.number = 1, show.conf.interval = FALSE, landscape = TRUE)

#swap in this command to see it in the console
print(Table1_Cor) 
```
## Results

Our sample included Asian American (*n* = 398), Latinx (*n* = 182), and Black (*n* = 133) participants. Visual inspection of the three variables of interest (negative affect, psychological distress, microaggressions) combined with formal evaluation of skewness and kurtosis suggested univariate normality.  Correlations between negative affect and psychological distress were quite strong; correlations with each of these variables and microaggressions were moderate.  Results are presented in Table 1.


## Practice Problems

The three exercises described below are designed to "meet you where you are" and allow you to challenge your skills depending on your comfort with statistics and R.

Regardless which you choose, you should:

* Create a tiny_df from a larger df
* Calculateand interpret descriptives for the continuously scaled variables
* Create the SPLOM (pairs.panels) of the continuously scaled variables
* Use the *apaTables* package to make an APA style table with means, standard deviations, and correlations
* Write up a mini-results section (APA style)

### Problem #1: Change the Random Seed

If this topic feels a bit overwhelming, simply change the random seed in the data simulation (at the very top), then rework the lesson exactly as written. This should provide minor changes to the data (maybe in the second or third decimal point), but the results will likely be very similar.

### Problem #2: 

Use the simulated data from the Lui [-@lui_racial_2020] study. However, select three continuous variables (2 must be different from mine) and then conduct the analyses.

Element                                  | Points Poss   | Points Earned
---------------------------------------- | ------------- |---------------
1. Create the tiny_df                    |      3        |               
---------------------------------------- | ------------- |---------------
2. Descriptives of tiny_df               |      3        |
---------------------------------------- | ------------- |---------------
3. SPLOM/pairs.panels                    |      3        |   
---------------------------------------- | ------------- |---------------
4. apaTables matrix                      |      3        |               
---------------------------------------- | ------------- |---------------
5. Mini-results                          |      5        |   
---------------------------------------- | ------------- |---------------
6. Explanation/discussion with a grader  |      5        |
---------------------------------------- | ------------- |---------------

---------------------------------------- | ------------- |---------------
**Totals                                 |     22        |             
---------------------------------------- |---------------|---------------

### Problem #3: 

Use data for which you have permission and access. This could be IRB approved data you have collected or from your lab; data you simulate from a published article; data from an open science repository; or data from other chapters in this OER.

Element                                  | Points Poss   | Points Earned
---------------------------------------- | ------------- |---------------
1. Create the tiny_df                    |      3        |               
---------------------------------------- | ------------- |---------------
2. Descriptives of tiny_df               |      3        |
---------------------------------------- | ------------- |---------------
3. SPLOM/pairs.panels                    |      3        |   
---------------------------------------- | ------------- |---------------
4. apaTables matrix                      |      3        |               
---------------------------------------- | ------------- |---------------
5. Mini-results                          |      5        |   
---------------------------------------- | ------------- |---------------
6. Explanation/discussion with a grader  |      5        |
---------------------------------------- | ------------- |---------------

---------------------------------------- | ------------- |---------------
**Totals                                 |     22        |             
---------------------------------------- |---------------|---------------s


### Other instructions
Please have all the elements of this assignment in this RMarkdown document (and folder).

During live grading the GTA will instruct you what points to put in the table, below.

When you upload your assignment to Canvas, please list all names on the assignment and list the points earned.  And put these also in the comments associated with the assignment.



Element                                  | Points Poss   | Points Earned
---------------------------------------- | ------------- |---------------
1. Create the tiny_df                    |      3        |               
---------------------------------------- | ------------- |---------------
2. Descriptives of tiny_df               |      3        |
---------------------------------------- | ------------- |---------------
3. SPLOM/pairs.panels                    |      3        |   
---------------------------------------- | ------------- |---------------
4. apaTables matrix                      |      3        |               
---------------------------------------- | ------------- |---------------
5. Mini-results                          |      5        |   
---------------------------------------- | ------------- |---------------
6. Explanation/discussion with a grader  |      5        |
---------------------------------------- | ------------- |---------------

---------------------------------------- | ------------- |---------------
**Totals                                 |     22        |             
---------------------------------------- |---------------|---------------



```{r include=FALSE}
sessionInfo()
```


