[["index.html", "ReCentering Psych Stats: Topics in Research Methods BOOK COVER", " ReCentering Psych Stats: Topics in Research Methods Lynette H Bikos, PhD, ABPP BOOK COVER An image of the book cover. It includes four quadrants of non-normal distributions representing gender, race/ethnicty, sustainability/global concerns, and journal articles "],["preface.html", "PREFACE Copyright with Open Access", " PREFACE If you are viewing this document, you should know that this is a book-in-progress. Early drafts are released for the purpose teaching my classes and gaining formative feedback from a host of stakeholders. The document was last updated on 24 Aug 2021 There are lectures accompanying each lesson. At present, these screencast of these lectures are from prior lecture notes and not directly from this OER. While the content should be parallel, you might find it to be somewhat discordant. I do plan to relecture these using the formatting of the OER; I just cant get to it this year. Please accept my apologies. Screencasted Lecture Link To center a variable in regression means to set its value at zero and interpret all other values in relation to this reference point. Regarding race and gender, researchers often center male and White at zero. Further, it is typical that research vignettes in statistics textbooks are similarly seated in a White, Western (frequently U.S.), heteronormative, framework. The purpose of this project is to create a set of open educational resources (OER) appropriate for doctoral and post-doctoral training that contribute to a socially responsive pedagogy  that is, it contributes to justice, equity, diversity, and inclusion. Statistics training in doctoral programs are frequently taught with fee-for-use programs (e.g., SPSS/AMOS, SAS, MPlus) that may not be readily available to the post-doctoral professional. In recent years, there has been an increase and improvement in R packages (e.g., psych, lavaan) used for in analyses common to psychological research. Correspondingly, many graduate programs are transitioning to statistics training in R (free and open source). This is a challenge for post-doctoral psychologists who were trained with other software. This OER will offer statistics training with R and be freely available (specifically in a GitHub respository and posted through GitHub Pages) under a Creative Commons Attribution - Non Commercial - Share Alike license [CC BY-NC-SA 4.0]. Training models for doctoral programs in HSP are commonly scholar-practitioner, scientist-practitioner, or clinical-scientist. An emerging model, the scientist-practitioner-advocacy training model incorporates social justice advocacy so that graduates are equipped to recognize and address the sociocultural context of oppression and unjust distribution of resources and opportunities (Mallinckrodt et al., 2014). In statistics textbooks, the use of research vignettes engages the learner around a tangible scenario for identifying independent variables, dependent variables, covariates, and potential mechanisms of change. Many students recall examples in Fields (2012) popular statistics text: Viagra to teach one-way ANOVA, beer goggles for two-way ANOVA, and bushtucker for repeated measures. What if the research vignettes were more socially responsive? In this OER, research vignettes will be from recently published articles where: the authors identity is from a group where scholarship is historically marginalized (e.g., BIPOC, LGBTQ+, LMIC[low-middle income countries]), the research is responsive to issues of justice, equity, inclusion, diversity, the lessons statistic is used in the article, and there is sufficient information in the article to simulate the data for the chapter example(s) and practice problem(s); or it is publicly available. In training for multicultural competence, the saying, A fish doesnt know that its wet is often used to convey the notion that we are often unaware of our own cultural characteristics. In recent months and years, there has been an increased awakening to the institutional and systemic racism that our systems are perpetuating. Queuing from the water metaphor, I am hopeful that a text that is recentered in the ways I have described can contribute to changing the water in higher education and in the profession of psychology. Copyright with Open Access This book is published under a a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. This means that this book can be reused, remixed, retained, revised and redistributed (including commercially) as long as appropriate credit is given to the authors. If you remix, or modify the original version of this open textbook, you must redistribute all versions of this open textbook under the same license - CC BY-SA. A GitHub open-source repository contains all of the text and source code for the book, including data and images. References "],["acknowledgements.html", "ACKNOWLEDGEMENTS", " ACKNOWLEDGEMENTS As a doctoral student at the University of Kansas (1992-2005), I learned that a foreign language was required for graduation. Please note that as one who studies the intersections of global, vocational, and sustainable psychology, I regret that I do not have language skills beyond English. This could have been met with credit from high school my rural, mid-Missouri high school did not offer such classes. This requirement would have typically been met with courses taken during an undergraduate program  but my non-teaching degree in the University of Missouris School of Education was exempt from this. The requirement could have also been met with a computer language (fortran, C++)  I did not have any of those either. There was a tiny footnote on my doctoral degree plan that indicated that a 2-credit course, SPSS for Windows would substitute for the language requirement. Given that it was taught by my one of my favorite professors, I readily signed up. As it turns out, Samuel B. Green, PhD, was using the course to draft chapters in the textbook (Green &amp; Salkind, 2014) that has been so helpful for so many. Unfortunately, Drs. Green (1947 - 2018) and Salkind (2947 - 2017) are no longer with us. I have worn out numerous versions of their text. Another favorite text of mine was Dr. Barbara Byrnes (2016), Structural Equation Modeling with AMOS. I loved the way she worked through each problem and paired it with a published journal article, so that the user could see how the statistical evaluation fit within the larger project/article. I took my tea-stained text with me to a workshop she taught at APA and was proud of the signature she added to it (a little catfur might have fallen out). Dr. Byrne created SEM texts for a number of statistical programs (e.g., LISREL, EQS, MPlus). As I was learning R, I wrote Dr. Byrne, asking if she had an edition teaching SEM/CFA with R. She promptly wrote back, saying that she did not have the bandwidth to learn a new statistics package. We lost Dr. Byrne in December 2020. I am so grateful to these role models for their contributions to my statistical training. I am also grateful for the doctoral students who have taken my courses and are continuing to provide input for how to improve the materials. The inspiration for training materials that re*center statistics and research methods came from the Academics for Black Survival and Wellness Initiative. This project, co-founded by Della V. Mosley, Ph.D., and Pearis L. Bellamy, M.S., made clear the necessity and urgency for change in higher education and the profession of psychology. At very practical levels, I am indebted to SPUs Library, and more specifically, SPUs Education, Technology, and Media Department. Assistant Dean for Instructional Design and Emerging Technologies, R. John Robertson, MSc, MCS, has offered unlimited consultation, support, and connection. Senior Instructional Designer in Graphics &amp; Illustrations, Dominic Wilkinson, designed the logo and bookcover. Psychology and Scholarly Communications Librarian, Kristin Hoffman, MLIS, has provided consultation on topics ranging from OERS to citations. I am alo indebted to Associate Vice President, Teaching and Learning at Kwantlen Polytechnic University, Rajiv Jhangiani, PhD. Dr. Jhangianis text (2019) was the first OER I ever used and I was grateful for his encouraging conversation. Financial support for this OER has been provided from: The Call to Action on Equity, Inclusion, Diversity, Justice, and Social Responsivity Request grant from the Association of Psychology Postdoctoral and Internship Centers (2021-2022). The *Diversity Seed Grant** from the Office of Inclusive Excellence and Advisory Council for Diversity and Reconciliation (ACDR) at Seattle Pacific University. The ETM Open Textbook &amp; OER Development Funding program from the Office of Education, Technology, &amp; Media at Seattle Pacific University. References "],["ReCintro.html", "Chapter 1 Introduction 1.1 What to expect in each chapter 1.2 Strategies for Accessing and Using this OER 1.3 If You are New to R", " Chapter 1 Introduction Screencasted Lecture Link 1.1 What to expect in each chapter This textbook is intended as applied, in that a primary goal is to help the scientist-practitioner-advocate use a variety of statistics in research problems and writing them up for a program evaluation, dissertation, or journal article. In support of that goal, I try to provide just enough conceptual information so that the researcher can select the appropriate statistic (i.e., distinguishing between when ANOVA is appropriate and when regression is appropriate) and assign variables to their proper role (e.g., covariate, moderator, mediator). This conceptual approach does include occasional, step-by-step, hand-calculations (only we calculate them arithmetically in R) to provide a visceral feeling of what is happening within the statistical algorithm that may be invisible to the researcher. Additionally, the conceptual review includes a review of the assumptions about the characteristics of the data and research design that are required for the statistic. Statistics can be daunting, so I have worked hard to establish a workflow through each analysis. When possible, I include a flowchart that is referenced frequently in each chapter and assists the the researcher keep track of their place in the many steps and choices that accompany even the simplest of analyses. As with many statistics texts, each chapter includes a research vignette. Somewhat unique to this resource is that the vignettes are selected from recently published articles. Each vignette is chosen with the intent to meet as many of the following criteria as possible: the statistic that is the focus of the chapter was properly used in the article, the authors identity is from a group where scholarship is historically marginalized (e.g., BIPOC, LGBTQ+, LMIC [low middle income countries]), the research has a justice, equity, inclusion, diversity, and social responsivity focus and will contribute positively to a social justice pedagogy, and the data is available in a repository or there is sufficient information in the article to simulate the data for the chapter example(s) and practice problem(s). In each chapter we employ R packages that will efficiently calculate the statistic and the dashboard of metrics (e.g., effect sizes, confidence intervals) that are typically reported in psychological science. 1.2 Strategies for Accessing and Using this OER There are a number of ways you can access this resource. You may wish to try several strategies and then select which works best for you. I demonstrate these in the screencast that accompanies this chapter. Simply follow along in the .html formatted document that is available on via GitHub Pages, and then open a fresh .rmd file of your own, copying (or retyping) the script and running it Locate the original documents at the GitHub repository . You can open them to simply take note of the behind the scenes script copy/download individual documents that are of interest to you fork a copy of the entire project to your own GitHub site and further download it (in its entirety) to your personal workspace. The GitHub Desktop app makes this easy! Listen to the accompanying lectures (I think sound best when the speed is 1.75). The lectures are being recorded in Panopto and should include the closed captioning. Provide feedback to me! If you fork a copy to your own GitHub repository, you can open up an editing tool and mark up the document with your edits, start a discussion by leaving comments/questions, and then sending them back to me by committing and saving. I get an e-mail notiying me of this action. I can then review (accepting or rejecting) them and, if a discussion is appropriate, reply back to you. 1.3 If You are New to R R can be oveRwhelming. Jumping right into advanced statistics might not be the easiest way to start. However, in these chapters, I provide complete code for every step of the process, starting with uploading the data. To help explain what R script is doing, I sometimes write it in the chapter text; sometimes leave hastagged-comments in the chunks; and, particularly in the accompanying screencasted lectures, try to take time to narrate what the R script is doing. Ive found that, somewhere on the internet, theres almost always a solution to what Im trying to do. I am frequently stuck and stumped and have spent hours searching the internet for even the tiniest of things. When you watch my videos, you may notice that in my R studio, there is a scRiptuRe file. I takes notes on the solutions and scripts here  using keywords that are meaningful to me so that when I need to repeat the task, I can hopefully search my own prior solutions and find a fix or a hint. 1.3.1 Base R The base program is free and is available here: https://www.r-project.org/ Because R is already on my machine (and because the instructions are sufficient), I will not walk through the instllation, but I will point out a few things. Follow the instructions for your operating system (Mac, Windows, Linux) The cran (I think cranium) is the Comprehensive R Archive Network. In order for R to run on your computer, you have to choose a location. Because proximity is somewhat related to processing speed, select one that is geographically close to you. You will see the results of this download on your desktop (or elsewhere if you chose to not have it appear there) but you wont ever use R through this platform. 1.3.2 R Studio R Studio is the desktop application I work in R. Its a separate download. Choose the free, desktop, option that is appropriate for your operating system: https://www.rstudio.com/products/RStudio/ Upper right window: Includes several tabs; we frequently monitor the Environment: it lists the objects that are available to you (e.g., dataframes) Lower right window: has a number of helpful tabs. Files: Displays the file structure in your computers environment. Make it a practice to (a) organize your work in small folders and (b) navigating to that small folder that is holding your project when you are working on it. Packages: Lists the packages that have been installed. If you navigate to it, you can see if it is on. You can also access information about the package (e.g., available functions, examples of script used with the package) in this menu. This information opens in the Help window. Viewer and Plots are helpful, later, when we can simultaneously look at our output and still work on our script. Primary window R Studio runs in the background(in the console). Very occasionally, I can find useful troubleshooting information here. More commonly, I open my R Markdown document so that it takes the whole screen and I work directly, right here. R Markdown is the way that many analysts write script, conduct analyses, and even write up results. These are saved as .rmd files. In R Studio, open an R Markdown document through File/New File/R Markdown Specify the details of your document (title, author, desired ouput) In a separate step, SAVE this document (File/Save] into a NEW FILE FOLDER that will contain anything else you need for your project (e.g., the data). Packages are at the heart of working in R. Installing and activating packages require writing script. 1.3.3 R Hygiene Many initial problems in R can be solved with good R hygiene. Here are some suggestions for basic practices. It can be tempting to skip this. However, in the first few weeks of class, these are the solutions I am presenting to my students. 1.3.3.1 Everything is documented in the .rmd file Although others do it differently, everything is in my .rmd file. That is, for uploading data and opening packages I write the code in my .rmd file. Why? Because when I read about what I did hours or years later, I have a permanent record of very critical things like (a) where my data is located, (b) what version I was using, and (c) what package was associated with the functions. 1.3.3.2 File organization File organization is a critical key to this: Create a project file folder. Put the data file in it. Open an R Markdown file. Save it in the same file folder. When your data and .rmd files are in the same folder (not your desktop, but a shared folder), they can be connected. 1.3.3.3 Chunks The R Markdown document is an incredible tool for integrating text, tables, and analyses. This entire OER is written in R Markdown. A central feature of this is chunks. The easiest way to insert a chunk is to use the INSERT/R command at the top of this editor box. You can also insert a chunk with the keyboard shortcut: CTRL/ALT/i Chunks start and end with with those three tic marks and will show up in a shaded box, like this: #hashtags let me write comments to remind myself what I did #here I am simply demonstrating arithmetic (but I would normally be running code) 2021 - 1966 ## [1] 55 Each chunk must open and close. If one or more of your tic marks get deleted, your chunk wont be read as such and your script will not run. The only thing in the chunks should be script for running R; you can hashtag-out script so it wont run. Although unnecessary, you can add a brief title for the chunk in the opening row, after the r. These create something of a table of contents of all the chunks  making it easier to find what you did. You can access them in the Chunks tab at the bottom left of R Studio. If you wish to knit a document, you cannot have identical chunk titles. You can put almost anything you want in the space outside of tics. Syntax for simple formatting in the text areas (e.g,. using italics, making headings, bold, etc.) is found here: https://rmarkdown.rstudio.com/authoring_basics.html 1.3.3.4 Packages As scientist-practitioners (and not coders), we will rely on packages to do our work for us. At first you may feel overwhelmed about the large number of packages that are available. Soon, though, you will become accustomed to the ones most applicable to our work (e.g., psych, tidyverse, lavaan, apaTables). Researchers treat packages differently. In these lectures, I list all the packages we will use in an opening chunk that asks R to check to see if the package is installed, and if not, installs it. if(!require(psych)){install.packages(&quot;psych&quot;)} ## Loading required package: psych ## Warning: package &#39;psych&#39; was built under R version 4.0.5 To make a package operable, you need to open it through the library. This process must be repeated each time you restart R. I dont open the package (through the library(package_name)) command until it is time to use it. Especially for new users, I think its important to connect the functions with the specific packages. #install.packages (&quot;psych&quot;) library (psych) If you type in your own install.packages code, hashtag it out once its been installed. It is problematic to continue to re-run this code . 1.3.3.5 Knitting An incredible feature of R Markdown is its capacity to knit to HTML, powerpoint, or word. If you access the .rmd files for this OER, you can use annotate or revise them to suit your purposes. If you redistribute them, though, please honor the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License with a citation. 1.3.4 tRoubleshooting in R maRkdown Hiccups are normal. Here are some ideas that I have found useful in getting unstuck. In an R script, you must have everything in order  Every. Single. Time. All the packages have to be in your library and activated; if you restart R, you need to reload each package. If you open an .rmd file and want a boxplot, you cannot just scroll down to that script. You need to run any prerequisite script (like loading the package, importing data, putting the data in the global environment, etc.) Do you feel lost? clear your global environment (broom) and start at the top of the R script. Frequent, fresh starts are good. Your .rmd file and your data need to be stored in the same file folder. These should be separate for separate projects, no matter how small. Type any warnings you get into a search engine. Odds are, youll get some decent hints in a manner of seconds. Especially at first, these are common errors: The package isnt loaded (if you restarted R, you need to reload your packages) The .rmd file has been saved yet, or isnt saved in the same folder as the data Errors of punctuation or spelling Restart R (its quick  not like restarting your computer) If you receive an error indicating that a function isnt working or recognized, and you have loaded the package, type the name of the package in front of the function with two colons (e.g., psych::describe(df). If multiple packages are loaded with functions that have the same name, R can get confused. 1.3.5 stRategies for success Engage with R, but dont let it overwhelm you. The mechanical is also the conceptual. Especially when it is simpler, do try to retype the script into your own .rmd file and run it. Track down the errors you are making and fix them. If this stresses you out, move to simply copying the code into the .rmd file and running it. If you continue to have errors, you may have violated one of the best practices above (Is the package loaded? Are the data and .rmd files in the same place? Is all the prerequisite script run?). Still overwhelmed? Keep moving forward by downloading a copy of the .rmd file that accompanies any given chapter and just run it along with the lecture. Spend your mental power trying to understand what each piece does. Then select a practice problem that is appropriate for your next level of growth. Copy script that works elsewhere and replace it with your datafile, variables, etc. The leaRning curve is steep, but not impossible. Gladwell(2008) reminds us that it takes about 10,000 hours to get GREAT at something (2,000 to get reasonably competent). Practice. Practice. Practice. Updates to R, R Studio, and the packages are NECESSARY, but can also be problematic. It could very well be that updates cause programs/script to fail (e.g., X has been deprecated for version X.XX). Moreover, this very well could have happened between my distribution of these resources and your attempt to use it. My personal practice is to update R, R Studio, and the packages a week or two before each academic term. Embrace your downward dog. Also, walk away, then come back. 1.3.6 Resources for getting staRted R for Data Science: https://r4ds.had.co.nz/ R Cookbook: http://shop.oreilly.com/product/9780596809164.do R Markdown homepage with tutorials: https://rmarkdown.rstudio.com/index.html R has cheatsheets for everything, heres one for R Markdown: https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf R Markdown Reference guide: https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf Using R Markdown for writing reproducible scientific papers: https://libscie.github.io/rmarkdown-workshop/handout.html LaTeX equation editor: https://www.codecogs.com/latex/eqneditor.php References "],["TrainMod.html", "Chapter 2 Training Models in Professional Psychology 2.1 Navigating this Lesson 2.2 The Push and Pull of Science and Practice 2.3 Training Models &amp; Accreditation 2.4 Suggestions for Practice", " Chapter 2 Training Models in Professional Psychology Screencasted Lecture Link This lesson compares and contrasts training models in professional psychology. To that end, I review: The push and pull of science and practice Training models (and accreditation) Scientist-practitioner Scholar practitioner Clinical scientist Local clinical scientist Programmatic differences as a function of training model The future of models  and one in particular The Research &amp; Dissertation Guidelines in the doctoral psychology programs at SPU. 2.1 Navigating this Lesson There is about 1 hour and 10 minutes of lecture. 2.1.1 Learning Objectives Learning objectives from this lecture include the following: Identify the key differences between training models. Distinguish one training model from another based on expected outcomes. Identify the place of the Local Clinical Science model, relative to other models. Describe the training model for your particular graduate program. What citations would you cite to defend any description or comparison? 2.1.2 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Bell, D. J., &amp; Hausman, E. M. (2014). Training Models in Professional Psychology Doctoral Programs (Chapter 3). In W. B. Johnson &amp; N. Kaslow (Eds.), The Oxford Handbook of Education and Training in Professional Psychology. Much of our first class will be spent talking about training models in graduate psychology. This chapter is an excellent review of the origin of training models, their defining characteristics, and how they strengthen as well as challenge our training programs. The authors have both been long-involved in the issue of training models and accreditation. 2.2 The Push and Pull of Science and Practice Meehls (1954, p. 4) catharsis regarding the dissociated state of science and practice is below. Well turn it into Readers Theater by following Strickers (1997) recommendation to substitute scientist for the statistical metnod and practitioner or the clinical method. If you were in my classroom I would ask or volunteers to be the NARRATOR, the advocate for the scientist (italics) and advocate forthe practitioner (bold). The (statistical method) scientist is often called operational, communicable, verifiable, public, objective, reliable, behavioral, testable, rigorous, scientific, precise, careful, trustworthy, experimental, quantitative, down-to-earth, hardheaded, empirical, mathematical, and sound. Those who dislike the method scientist consider them to be mechanical, atomistic, additive, cut and dried, artificial, unreal, arbitrary, incomplete, dead, pedantic, fractionated, trivial, forced, static, superficial, rigid, sterile, academic, oversimplified, pseudoscientific, and blind. The (clinical method) practitioner, on the other hand, is labeled by their proponents as dynamic, global, meaningful, holistic, subtle, sympathetic, configural, patterned, organized, rich, deep, genuine, sensitive, sophisticated, real, living, concrete, natural, true to life, and understanding. The critics of the (clinical method) practitioner are likely to view them as mystical, transcendent, metaphysical, super-mundane, vague, hazy, subjective, unscientific, unreliable, crude, private, unverifiable, qualitative, primitive, prescientific, sloppy, uncontrolled, careless, verbalistic, intuitive, and muddleheaded. 2.3 Training Models &amp; Accreditation APA accredited programs must (but most all grad psych programs do): define and articulate their own training philosophies, demonstrate that the outcomes of the training are consistent with the model do so because of the need for (and value of) public accountability All currently accredited doctoral programs in clinical have a pure model affiliation or some variation thereof. Most common models: clinical scientist, scientist-practitioner, with updated proposal for scientist-practitioner-advocate (Mallinckrodt et al., 2014) practitioner-scholar models 2.3.1 Scientist~Practitioner (SP) Model The scientist~practitioner model is also known as the Boulder Model. It originated in 1949 with formal articulation in 1950 (Raimy, 1950). It is characterized by the following: Primary goal: equal provision of extensive training in psychological research and the applications of that research to eventual practicethat is, to the creation of the SP psychologist (Cherry et al., 2000). Began in clinical psychology; prominent training model in school, counseling, and I/O psych programs Model re-articulated at the National Conference on SP Education and Training for the Professional Practice of Psychology, Gainesville, FL, 1990 (Belar &amp; Perry, 1992). Major theme: SP  summation; SP  continuum; SP = integration. New symbols: not S-P, but SXP or S~P Major theme: The graduate of this training model is capable of functioning as an investigator and as a practitioner, and may function as either or both, consistent with the highest standards in psychology. Training components of the SP model (Belar &amp; Perry, 1992): Didactic scientific Didactic practice core Experiential scientific Professional practice experiential Integration of Education &amp; Training System components (faculty, setting, evaluation procedures) In spite of this idealism, many argue that the S~P model is really an S model (e.g., Stricker &amp; Trierweiler, 2006). Just what evidence is there or this? A mixed methods study (Ridley &amp; Laird, 2015) surveyed training directors in counseling psychology programs. Training directors indicated the degree to which each of nine program components fell in the continuum of science-to-practice. Table 6 in the manuscript shows the results (and is worth a look). Overall the programs leaned heavily toward science with four of the criteria being rated as heavily science. These included Statistics and resaerch methodology Psychology core course Resaerch experiences Dissertation experiences Only practica courses were rated as heavily practice. The remaining criteria fell between the two. These included: Criteria for student evaluations. Counseling psychology core courses Our program overall Diagnostic/assessment courses. 2.3.2 Scholar-Practitioner (SCH-P) Model The scholar-practitioner model is also known as the Vail model. It originated in 1973 when the National Institute for Mental Health and the American Psychological Association met in Vail, Colorado. It is characterized by the following: Primary goal: the preparation for delivery of human services in a manner that is effective and responsive to individual needs, societal needs, and diversity (McHolland, 1992, p. 159). Operationalized as the capacity to conduct disciplined inquiry (rather than producing controlled lab or field research) Ivey and Leppaluoto (1975) summarized the major emphases of this model; the original summary is found in Korman (1974): Awareness of values; not promotion of right values Attention to human diversity and culture Scientist practitioner: professional training as a legitimate alternative. Individual v program training (e.g., continuing education [CE]) Specifically, the conferands concluded that when primary training emphasis is on the production of new knowledge, the Ph.D. is appropriate; when primary emphasis is on professional services, evaluation, and improving services, the Psy.D. is appropriate. 2.3.3 Clinical Scientist Model The clinical science model was created by the Academy of Psychological Clinical Science in 1974. It is characterized by the following: Primary goal: to provide training in the production of scientific research on clinical problems and its application to those problems (Academy of Psychological Clinical Science, 1997). Clinical science is defined as a psychological science directed at the promotion of adaptive functioning; at the assessment, understanding, amelioration, and prevention of human problems in behavior, affect, cognition or health; and at the application of knowledge in ways consistent with scientific evidence. The Academys emphasis on the term science underscores its commitment to empirical approaches to evaluating the validity and utility of testable hypotheses and to advancing knowledge by this method. A flavor of this model can be found in a McFalls (1991) Manifesto for a Science of Clinical Psychologyhttp://apsychoserver.psych.arizona.edu/JJBAReprints/PSYC621/McFall_Manifesto_1991.pdf). McFcall declared that Scientific clinical psychology is the only legitimate and acceptable form of clinical psychology should be a Cardinal Principle. To that end: First Corollary: Psychological services should not be administered to the public (except under strict experimental control) until they have satisfied these four - - The exact nature of the service must be described clearly. The claimed benefits of the service must be stated explicitly. These claimed benefits must be validated scientifically Possible negative side effects that might outweigh any benefits must be ruled out empirically. Second Corollary: The primary and overriding objective of doctoral training programs in clinical psychology must be to produce the most competent clinical scientists possible. Change is constant;PCSAS offers an accreditation program that competes with APAs. 2.3.4 Local Clinical Scientist Model (LCS) The local clinical scientist model emerged in a series of writing (Stricker, 1997; Stricker &amp; Trierweiler, 2006, 1995; Trierweiler et al., 2010; Trierweiler &amp; Stricker, 1998). It is characterized by the following: Elaborates, extends, optimizes, makes real the Boulder scientist-practitioner model A scientific approach and inquiring attitude of curiosity, skepticism, hypothesis testing and reframing within the local setting Breaking it down: clinical scientist reflects our commitment to psychology as both a scientific discipline and a healthcare profession. local refers to the particular application of general science, within local cultures, including the idiographic aspects of persons, families, and communities, in specific space-time and relational contexts 2.3.5 And What Does It Mean? Norcross et al.(2020) evaluated 20-year trends of counseling psychology programs in terms of program, student, and faculty comparisons  and also compared it to clinical psychology. The tables in the Norcross et al. manuscript are worth reviewing. Generally results demonstrated: there are more applicants to research-oriented programs a fewer percentage of students are to research-oriented programs there is more funding in research oriented programs there are non-significant differences for gender there is a lower percent of students of color in practice-oriented programs there is a shorter time required to complete practice oriented programs GREs are higher in research oriented programs Regarding differences between counseling psychology and clinical psychology programs, Norcross et al.(2020) reported that there were non-significant differences in the number of incoming students each year, but that there was greater numbers of applications received and, thereore, a smaller proportion of students accepted in clinical psychology programs. There was not a statistically significant diference in the percentage of students receiving full tuition waivers and assistantships. Regarding student characteristics, clinical psychology programs had somewhat higher GRE scores and students were more likely to enter having completed a bachelors degree. Regarding counseling psychology programs, more students had completed a masters level degree. There were more female students in clinical psychology programs; there were more ethnic minority students and international students in counseling psychology programs. Regarding theoretical orientation, counseling psychology programs were more likely to be psychodynamic/psychoanalytic, family systems/systems, and existential/humanistic. Clinical psychology programs were more likely to be applied behavioral analysis/radical behavioral and cognitive/cognitive-behavioral.Clinical psychology programs reported a stronger research-practice emphasis. Cherry et al. (2000) examined outcomes related to training model. Perhaps not surprisingly, research and publication productivity was highest among programs with a clinical scientist training model, followed by the scientist-practitioner training model, followed by the scholar-practitioner model. Service delivery was the the opposite order. Regarding post-doctoral employment settings, graduates from clinical psychology programs often held employment in academic settings. Graduates of scholar-practitioner programs most often held employment in community mental health centers and other/multiple settings. Graduates from scientist-practitioner programs had more of a diverse profile in post-doctoral employment. A figure reflecting the research/science and practice/service continuum 2.3.6 What Lies Ahead? Mallinckrodt et al. (2014) has proposed a scientist-practitioner-advocate training model for doctoral training in professional psychology, designed to more effectively meet the needs of clients whose presenting problems are rooted in a sociocultural context of oppression and unjust distribution of resources and opportunities. This model has been represented with three intersecting circles: where science and practice overlap, science informs practice and practice generates research ideas, where practice and advocacy overlap, there is advocacy for clients, empowering them to advocate for themselves, where advocacy and science overlap, there is action resaerch and research as advocacy, at the center where all three overlap is a practicum in social justice advocacy. The scientist-practitioner-advocate model prioritizes four outcomes: Developing an understanding how the context of social problems impacts the lives of individuals; Demonstrating skills in the methods of social action research and be able to use empirical skills as tools for advocacy and to promote social change; Developing effective interventions targeted at the level of institutions or systems influencing public policy decisions and evaluating the effectiveness of these interventions; and Learning to work with individual clients to help them make informed choices about the cost and benefits of engaging in advocacy for themselves. The University of Tennessee Counseling Psychology Program and provides a practical example of how it has been operationalized in their program. Accredited programs are required to provide details about their training models in their program materials. These are often foundin doctoral handbooks, research and dissertation guidelines, and clinical trainng guidelines. 2.4 Suggestions for Practice If you are in a graduate training program in psychology (or considering the possibility of further trainng and education): Does your program have a specified and articulated model? If yes, what is it? How does it compare to the descriptions in this lesson? If no, based on what you know about the program how would you describe it? Interview at least two faculty. How do they identify and describe the trainng model of the program? Do the programmatic characteristics and outcomes align with those reported in Norcross et al. (2020) and Cherry et al (2000)? References "],["PHoS.html", "Chapter 3 Epistemology and Philosophy of Science 3.1 Navigating this Lesson 3.2 Core Themes in Research Methodology 3.3 Defining Research (And [Some Of]) Its Key Concepts 3.4 Philosophy of Science as it Relates to Research Methodology", " Chapter 3 Epistemology and Philosophy of Science Screencasted Lecture Link This lesson provides a high level review of epistemology (including the contribution of race-based epistemologies) and philosophy of science and considers the differences in these paradigms. 3.1 Navigating this Lesson There is about 45 minutes of lecture. 3.1.1 Learning Objectives Learning objectives from this lecture include the following: Identify, define, and provide examples of the standard ways of knowing. * Describe how a race-based epistemology (e.g., Black feminist epistemology) could add value to a research study. Distinguish between emic and etic. Define critical research concepts: components of science, methodology, research design, parsimony, plausible rival hypotheses, statistical inference. Define four primary philosophies of science, being able to identify the epistemology, axiology, rhetorical structure, and methodology for each. 3.1.2 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Jhangiani, R. S., Chiang, I.-C. A., Cuttler, C., &amp; Leighton, D. C. (2019). Research Methods in Psychology. https://doi.org/10.17605/OSF.IO/HF7DQ Chapter 1: Methods of Knowing Chapter 2: Understanding Science Chapter 3: Goals of Science These quick chapters are framing for some of the deeper concepts. Rajack-Talley, T. A., Smith, S. E., Best, L., Della, L. J., DSilva, M. U., Potter, D. A., &amp; Carthan, Q. (2017). Epistemological inclusiveness in researching the African American community. International Journal of Social Research Methodology: Theory &amp; Practice, 20(4), 411423. https://doi.org/10.1080/13645579.2016.1187460 This is an incredible article describing how a multi-ethnic, multi-disciplinary team engaged race-based epistemology to improve their NIH study. Gephart, Jr., R. P. (2013). Doing research with words: Qualitative methodologies and industrial/organizational psychology. In J. M. Cortina &amp; R. S. Landis (Eds.), Modern Research Methods for the Study of Behavior in Organizations (pp. 266318). Taylor &amp; Francis Group. http://ebookcentral.proquest.com/lib/spu/detail.action?docID=1154313 More recent than the Ponterotto article and written for an I/O audience. Excellent review of philosophies of science. Gephart and Ponterotto (below) chop up philosophies of science a bit differently. Ponterotto, J. G. (2005). Qualitative research in counseling psychology: A primer on research paradigms and philosophy of science. Journal of Counseling Psychology, 52, 126-136. Although the primary purpose of the ms is to introduce a special JCP section on Qualitative Methodology, Ponterotto does an excellent job of defining research paradigms and then contrasting the primary approaches. 3.2 Core Themes in Research Methodology But first a bicycling vignette What would you think of allowing cyclists to have the option of treating stop signs as yield signs? What are your first impressions? Think for a minute what you know about riding a bicycle, where you know it from, and then what you would think about freeing up the stop-sign rule to let cyclists pass through (without a full stop) if it were safe to do so. 3.2.1 Ways of Knowing Epistemology: the branch of philosophy that studies the nature of knowledge, its presuppositions and foundations, and its extent and validity. One epistemological interest is in determining how we know what we know. Jhangiani (2019) and colleages listed five sources of knowledge. There are benefits and liabilities to each of these: Intuiton: relying on emotions and instincts; believing what feels true. Because instincts are driven by cognitive and motivational biases, they can be wrong. When weighing alternatives and thinking of all the different possibilities can be paralyzing, some intuitive decisions are superior to those based on analyses. Authority: accepting new ideas because an authority figure states it is true (parents, media, doctors, religious officials, the government, your professor ). If authorities are wrong or corrupt, following without questioning is problematic. If authorities are correct, following is time-saving and more efficient. Rationalism: using logic and reasoning to acquire new knowledge. Premises are stated and logical rules are followed to arrive at sound conclusion. If the premises are wrong or there is an error in logic, then the conclusion is invalid. If the premises are correct and logical rules are followed appropriately  it works! Empiricism: acquiring knowledge through observation and experience. We are limited in what we can experience (e.g., the world as flat) and observe and our senses deceive us; our prior experiences can alter perception. Empiricism is at the heart of the scientific method. The Scientific Method: A process of systematically collecting and evaluating evidence to test ideas and answer questions. Scientists engage systematic empiricism to make careful observations under various controlled conditions in order to test their ideas; they use rationalism to arrive at valid conclusions. The most likely method to arrive at valid conclusions/knowledge Its costly  time, resources. And cannot be applied to all questions  only empirical ones. Jhangiani et al.s (2019) five categories have a long history: Cohen and Nagels (1934) Sources of Knowledge included: Personal Observation and Experience Intuition Belief and tradition Authority Science Back to the bicycling vignette Theres more to this story. As of October 1st, 2020, cyclists in Washington State have been able to treat stop signs (not stoplights, railway crossings, or stop signal displayed by school busses) as yield signs (Dahl, 2020, 2020). The two articles from the Bellingham Herald walk us through some of the ways of knowing that led the Washington legislature to its widely passing margins (77 to 20 House; 44 to 1 Senate; (Fucoloro, 2020)). Lets think through the ways of knowing to understand the components that brought about this new law. Intuition: Depending on your own emotions and instincts, you may have widely-varying impressions. Mine? YES! That will make my life easier  and other drivers wont be angry when I lose momentum in the slowing and stopping. On the other hand, drivers may get really mad if they think Im breaking the law. Experience: Its my experience that Im more efficient (faster, smoother) if I can slow-through a stop-sign; particularly on right turns. This in turn, would make it faster for drivers. Authority: Idaho passed a similar in 1982 (dubbed the Idaho stop), Delaware in 2017 (the Delaware Yield), Oregon in 2019. Empiricism: Many cycling accidents happen in intersections. Traveling quickly through an intersection minimizes risk. Thus, momentum matters. Dahl (2020)gathered his own data. After a complete stop, it took 5.4 seconds to clear the intersection; entering at 5mph took only 3.8 seconds. This is 30% of time spent in one of the most probable places for cyclist/driver collisions. The Scientific Method: A year after the Idaho law went into effect, bicycle injuries dropped 14%. A UC Berkeley transportation researcher (Jason Meggs) found that cyling was 30% to 60% safer in Boise (home of the Idaho Stop law) than in Sacramento and 150 to 252 times safer than in Bakersfield California. Things to ponder: How would you have voted? Are there arguments for fairness/equity/equality in this argument (e.g., bicycles should have to follow same rules as cars)? 3.2.2 A Faith-Based Model For a faith-based, Methodist, take, John Wesley built on the Anglican faith tradition by adding a fourth emphases (experience), to create what is now termed the Wesleyan Quadrilateral (Glossary, n.d.). Scripture: defined as the primary source and standard for Christian doctrine Tradition: experience and the witness of development of growth of the faith through the past centuries and in many nations and cultures Experience: the individuals understanding and appropriating of the faith in the light of his or her own life. Reason: discernment and cogent thought. These traditions are clearly White, Western, and male. There are, of course, other ways do ask the question How do we know? As well as different answers to the question. 3.2.3 Race-Based Epistemologies Rajack-Talley et al. (2017) address this in a paper describing how they were intentional to include researchers with different epistemologies (race-based epistemologies) in an NIH-funded study of three Black communities in Kentucky. The NIH-study (Della et al., 2016) was a multi-staged, mixed methods, NIH-funded study examining individual, community, and cultural-level determinants of increasing fruit and vegetable consumption in Black residents in two low-income cities in Kentucky (Louisville, Hopkinsville). Proponents of race-based epistemologies argue: If the life experiences of African descent are integral to the analysis of research, then there should be some degree of an Afro-centric, Black, or race-based epistemological framework This includes the adoption of the emic approach that recognizes there are distinct historical and cultural experiences of African people; the emic approach includes the communitys understandings and interpretations of their conditions and experiences Outsiders who are researching the other are wise to maintain a critical relationship to the research topic (and population) through self-reflexivity (self-reflection by the researchers and acknowledgement that there are differences between the researcher and those being studied). One distinction is the difference in insider and outsider perspectives: * etic: - standing far enough away, on the outside, - with the purpose of observing similarities/differences from other cultures; - the primary interest is in testing hypotheses, identifying common/universal aspects of human behavior that transcend cultural differences. - assumes all cultures can be observed as generalizable phenomena with comparable features and universalistic measures * emic: - standing on the inside - with the purpose of identifying culture-specific elements or human behavior that are not comparable across cultures - measures are relative - argues that meaningful distinctions can only be made by people within the cultures - assumes that the best way to understand a culture is from the perspectives and values of those being observed Black feminist epistemology (as cited in (Hill Collins, 2000)) as an example of a race-based epistemology Concrete experiences are treated as a criterion of meaning Dialogues are used in assessing knowledge claims An ethic of caring is developed An ethic of personal accountability is accepted 3.3 Defining Research (And [Some Of]) Its Key Concepts Science is generally characterized by three components (Jhangiani et al., 2019): Systematic empiricism: planning, making, recording, analyzing observations of the natural world Empirical questions: concerning the way the world is not the way the world ought to be. Public knowledge: the data contributes to public knowledge; publication in academia (sharing knowledge and self-correcting); open science movement. The purpose of research is to draw valid inferences about the relationships between variables (Kazdin, 2017) Methodology the diverse principles, procedures, and practices that govern research. those practices that help to arrange the circumstances so as to minimize ambiguity in reaching the inferences. more than a compilation of specific practices, procedures, and strategies. a way of thinking Research Design. The plan or arrangement used to examine the question of interest (research design is subordinate to the concept of methodology). Parsimony. This concept is sometimes referred to the principle of economy, the principle of unnecessary plurality, the principle of simplicity, and Occams razor). Parsimony directs us to select the simplest version or account of the data among the alternatives that are available. Parsimony means that plurality should not be posited without necessity (Occams razor) Parsimony asks, Must we introduce new concepts to explain the data? What about new variables? Plausible Rival Hypotheses An interpretation of the results of an investigation on the basis of some other influence than the one the investigator has studied or wishes to discuss. Are there other interpretations that are plausible to explain the findings? Statistical inference related to experimentation because of the extensive reliance on statistical tests in research to draw conclusions from the data. statistical controls help to reduce the plausibility of rival interpretations of the results. agreed-upon decision rules At the completion of a study the explanation one wishes to provide ought to be the most plausible interpretation. This is achieved not by arguing persuasively, but rather by designing the study in such a way that other explanations do not seem very plausible or parsimonious (Kazdin, 2017). 3.4 Philosophy of Science as it Relates to Research Methodology Philosophy of Science Considers the logical and epistemological underpinnings of the scientific method in general. Historically, experimentation has been closely tied to philosophical thought. The very notion of hypothesis derives from philosophy. (among other things) reveals fundamental limitations in the logical underpinnings of observational and experimental methods. Two great articles that were written about qualitative methods, provide an accessible and concise review of philosophy of science as it connects to research in clinical (Ponterotto, 2005) and industrial-organizational (R. P. Gephart Jr., 2013) psychology. Much of this chapter is based on these articles. Paradigm A set of interrelated assumptions about the social world which provides a philosophical and conceptual framework for the organized study of that world. The paradigm sets the context for an investigators study. Positivism is the research paradigm that will guide most of our work in this class. A form of philosophical realism adhering closely to the hypothetico-deductive model. Primary goal: explanation that leads to prediction and control of phenomena. The received view (the one everyone is working under) There is one, true, knowable reality. Postpositivism Acknowledge an objective reality that is only imperfectly apprehendable; thus we can never fully capture a true reality (although it exists). While positivists stress theory verification, postpositivists engage in theory falsification. Positivism &amp; Postpositivism shared variance Explanation that leads to prediction and control. Emphasis of cause-effect linkages. An objective, detached, researcher role. Operation from nomothetic (application to people generally) and etic (universal laws and behaviors that transcend nations and cultures and apply to all humans) perspectives. Primary foundation/anchor for quantitative research. Constructivism  Interpretivism Relativist position assumes multiple, apprehendable, and equally valid realities. Reality is constructed. Hermeneutical approach  researcher/participant dialogue Meaning is hidden and must be brought to the surface through deep reflection. Goals are idiographic (applying to the individual) and emic (constructs or behaviors that are unique to an individual, sociocultural context, that are not generalizable). Emphasis on understanding the Erlebnis (lived experience) Critical-Ideological Serves to disrupt and challenge the status quo Paradigm is one of emancipation and transformation The researchers proactive values are central to the task, purpose, and methods of research Critical theory is traced to the 1920s at the Institute of Social Research at the University of Frankfurt. In Nazi-controlled Germany, the scholars fled to California to be shocked by American cultureby the contradictions between progressive American rhetoric of egalitarianism and the reality of racial and class discrimination. There is no single critical theory; a criticalist use his/her work as a form of cultural or social criticism. 3.4.1 Paradigmatic Impact on Onology, Epistemology, Axiology, Rhetorical Structure, and Methodology Ontology: the nature and reality of being. Answers the questions, What is the form and nature of reality? What can be known about reality? Positivists: There is one true reality that is apprehendable, identifiable, measurable (i.e., naïve realism). Post positivists: There is one true reality, but it can only be apprehended and measured imperfectly (i.e., critical realism). Constructivistsinterpretivists: There are multiple, constructed realities (i.e., relativism). Reality is subjective and influenced by the context of the situation, namely the individuals experience and perceptions, the social environment, and the interaction between the individual and the researcher. Criticalists: Reality is constructed within a social-historical context. The criticalist focuses on power-relations. They will assume that marginalized clients are likely have different levels of access and will present research data to pressure those in power to change. Epistemology: the relationship between the knower (research participant) and the would be knower (researcher). Positivists: emphasize dualism (i.e., researcher and the research participant and topic are assumed to be independent of one another) and objectivism (i.e., by following rigorous, standard procedures, the participant and topic can be studied by the researcher without bias). Post positivists: advocate a modified dualism/objectivism. The researcher may have some influence on that being researched, but the objectivity and researcher-subject independence remain important guidelines for the research process. Constructivists-interpretivists: advocate a transactional and subjectivist stance that maintains that reality is socially constructed, and therefore, the dynamic interaction between researcher and participant is central to capturing and describing the lived experience of the participant. Criticalists: concern with dialogic (gaining research insight through interaction) and dialectic (transforming research participants toward empowerment and emancipation). Collaboration with the research participants includes the goal of helping them gain insights that contribute toward their own liberation. Axiology: the role of researcher values in the scientific process. Positivists/post positivists: There is no place for values in the research process. The psychology researcher should remain emotionally detached from the investigative inquiry. Values, hopes, expectations, feelings have no place in scientific inquiry. Standardized, systematic investigative methods allowed elimination and/or strict control over any influence the researcher may have on the process. Constructivists-interpretivists: Maintain that the researchers values and lived experience cannot be divorced from the research process. The researcher should acknowledge, describe, and bracket his/her values, but not eliminate them. Criticalists: Explicitly hope and expect that their value biases influence the research process and outcome. A preset goal of the research is to empower participants to transform the status quo and emancipate themselves from ongoing oppression. Rhetorical Structure: the language used to present the procedures and results of research to ones intended audience. Rhetoric flows closely from ones epistemological and axiological stance. Positivist/Post positivists: Rhetoric is precise and scientific, presented in an objective manner. Constructivist-interpretivists/Criticalists: Final research report is in first person and often personalized. The researchers own experience, expectations, biases, and values are detailed comprehensively. Methodology: the process and procedures of the research. Positivists/Post positivists: attempt to simulate, as closely as possible, strict scientific methods and procedures where variables are carefully controlled or manipulated and where the researchers emotional or expectant stance on the problem under the study is irrelevant. Heavy reliance on true experiments and analog methods; quasi-experimental methods when no alternative is available. Constructivist-interpretivists/Criticalists: embrace naturalistic designs in which the researcher is ensconced in the community and day-to-day life of their research participants. Research methods include in-depth face-to-face interviewing and participant observation. One of Ponterottos (2005) finest moments! It is important that counseling researchers understand and clearly explicate their operating paradigm in the reporting of studiesit is essential that researchers, as well as journal editorial board members and grant reviewers locate research studies within a specific research paradigm. (p. 132). 3.4.2 Things Im Thinking About Why is it important to include race-based epistemologies? Mistrust comes from factual and perceived instances of exploitation and discrimination in a history of medical abuse, racism, failure to provide information/fully-informed-consent, racial stigmas, poor recruitment (Rajack-Talley et al., 2017) Although these recommendations can be seen as simply good field research, they are particularly important in researching the African American community because of the groups history and because more recent data collection has been used to negatively depict this racial group ((Rajack-Talley et al., 2017) p. 413). The Rajack-Talley et al. (2017) manuscript demonstrates how a multi-ethnic and multi-disciplinary team worked together to develop approaches that contributed to success in a complex NIH-funded research project from participation, engagement, and interpretation of results. Techniques included self-reflexivity, transect walks, conducting interviews in participants homes or familiar places with Black team members, collecting data in community locations including other trusted members of the community (e.g., family, friend, pastor, barber). Finally, let me recommend a very cool (38-minute) episode of Hidden Brain where Shankar Vedantam talks with researchers about the benefits of diversity on outcomes  including scientific research: References "],["Experimental.html", "Chapter 4 Experimental Design 4.1 Navigating this Lesson 4.2 In the Beginning There Was 4.3 Quasi-Experimental Designs 4.4 Threats to Internal Validity 4.5 Experimental Designs 4.6 The Validity Family 4.7 Defining External Validity 4.8 Balancing Internal and External Validity 4.9 Defining Construct Validity 4.10 Statistical Conclusion Validity 4.11 Answer Key", " Chapter 4 Experimental Design Screencasted Lecture Link This lesson focuses on  4.1 Navigating this Lesson There is about 1 hour of lecture. 4.1.1 Learning Objectives Learning objectives from this lecture include the following: Starting with a simple post-test only design, identify limitations and remedies that lead, incrementally, to more robust conclusions with regard to ruling out confounds and plausible rival hypotheses. Define internal, external, construct, and statistical conclusion validity and well as each of their subtypes. In the context of research design vignettes, specify the threats to validity and identify potential remedies. Discuss the tension between internal and external validity (and its connection to efficacy and effectiveness research). Support the discussion with citations. 4.1.2 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Jhangiani, R. S., Chiang, I.-C. A., Cuttler, C., &amp; Leighton, D. C. (2019). Research Methods in Psychology. https://doi.org/10.17605/OSF.IO/HF7DQ Chapter V: Experiment basics (23), Experimental design (24), Experimentation and validity (25), practical considerations (26) Chaper VIII: One group designs (38), Non-equivalent group designs (39) Brewer, M. B. (2000). Research design and issues of validity. In H. T. Reis &amp; C. M. Judd (Eds.), Handbook of research methods in social and personality psychology. Cambridge University Press. A favorite chapter on validity. Both accessible and rigorous. 4.2 In the Beginning There Was The backbone of psychology, rightly so, rests on randomized-studies, analyzed by analysis of variance (Kenny, 2019) Because I give these lectures in our analysis of variance class, this chapter is: located in positivist and post-positivist philosophies of science presumes there is the aspirational goal of inferring causality It is impossible to discuss causality or ANOVA without discussion of validity. In (1957), Campbell introduced the concepts of internal and external validity. Campbell and Stanley (1963) expanded these ideas. More than a decade later, Cook and Campbell (1979) introduced construct and conclusion (aka statistical conclusion or statistical conclusive) validity. In 2002, those discussions were extended in Shadish, Cook, and Campbells (2002) text, Experimental and quasi-experimental designs for generalized causal inference. This path of articles often focuses on methods associated with the research design. In his (2019) article on enhancing validity in psychological research, Kenny argued for sophisticated statistical approaches (e.g., structural equation modeling, dyadic analysis, mediation) that also support causal inference. However, the focus of our class is the research design and the use of the ANOVA family of statistics. As we talk through todays topics, well use the Tran and Lee (2014) experimental manipulation of the exceptionalizing stereotype with a sample of Asian and Asiam American individuals. In this experiment, Asian American participants (all &lt; 26 y.o., having arrived in the U.S. by age 12) were assigned to three different conditions where a White confederate delivered one of three messages: Nice talking to you. You speak English well  low racial loading Nice talking to you. You speak English well for an Asian  high racial loading Nice talking to you  control There were multiple outcome evaluations in the study: Pre &amp; post-interaction (before and after hearing the microaggression) Evaluation: How positive is your impression of this person? Perceived acceptance: How much do you think this person will like you? Enjoyable: How enjoyable do you believe the interaction will be? Similar: How similar do you think your interaction partner will be? Post-interaction only (after hearing the microaggression) Accurate: how accurate the participant believed the White confederates impression was Additional talk time: how much longer they would continue the interaction Group Assignment Pre-test observation Manipulation Post-test observation Low racial loading Random Evaluation, Perceived Acceptance, Enjoyable, Similar Yes: Nice talking to you. You speak English well. Evaluation, Perceived acceptance, Enjoyable, Similar, Accuracy, Additional talk time High racial loading Random Evaluation, Perceived Acceptance, Enjoyable, Similar Yes: Nice talking to you. You speak English well for an Asian. Evaluation, perceived acceptance, Enjoyable, Similar, Accuracy, Additional talk time Control Random Evaluation, Perceived Acceptance, Enjoyable, Similar Yes: Nice talking to you. Evaluation, perceived acceptance, Enjoyable, Similar, Accuracy, Additional talk time Tran and Lees (2014) study is an experiment. However, well imagine different research designs and use them to illustrate threats to the validity of the conclusions. 4.3 Quasi-Experimental Designs 4.3.1 One-group posttest only design: A treatment is implemented (or an IV is manipulated) and a dependent variable (DV) is measured once after the treatment is implemented. Hypothetical scenario Group Assignment Pre-test observation Manipulation Post-test observation Low racial loading Not applicable None Yes: Nice talking to you. You speak English well. Accuracy, Additional talk time This the weakest type of quasi-experimental design. Without a control group, we cannot tell if the degree of additional talk time would be different if the racial loading had been different. Without a pre-test (and measures conducive to the pretest) we cannot know if the Asian American participants reactions change as a function of the microaggression How does this change if we add a pretest? 4.3.2 One-group pretest-posttest design: The DV is measured once before the treatment/intervention/manipulation is implemented and once after the treatment/intervention/manipulation. Group Assignment Pre-test observation Manipulation Post-test observation Low racial loading Not applicable Evaluation, Perceived Acceptance, Enjoyable, Similar Yes: Nice talking to you. You speak English well. Evaluation, Perceived Acceptance, Enjoyable, Similar Now we can at least estimate if there has been change in the score from pre- to post-test. We cannot conclude this with any certainty  because we do not know if this would have changed as a function of the treatment/intervention/manipulation. Our inability to draw causal inferences has to do with threats to internal validity. 4.4 Threats to Internal Validity 4.4.1 Defining Internal Validity The veracity of the claim of a cause-effect relationship. Are changes in the DV produced by variations in the IV? X &gt; Y Primary concern: provide evidence of causal linkages. Advanced cognitive organizer (or a spoiler alert): a genuine RCT with zero attrition solves most problems associated with internal validity. 4.4.2 Threats to Internal Validity as a Function of One-Sample Designs History: any event occurring in or outside of the experiment (other than the IV) that may account for the results. Tran and Lee (2014): A pre-test defines a period of time and a control group controls for any historical interference (e.g., national levels of racism connected to COVID-19) In other research: 911 occurred in the midst of my longitudinal study on expats (no control group) Commonly occurs in: one-group designs (post-only, or pre-post) Remedy: no-treatment control group with the same schedule Maturation: changing over time; only a problem if the design cannot distinguish the effects of maturational changes from the intervention. Tran and Lee (2014): Similarly, a pre-test defines a period of time and a control group controls for any developmental change/growth In other research: expats in my longitudinal study increase their Turkish language skills (just b/c they live in Turkey) Commonly occurs in: one-group designs (post-only, or pre-post) Remedy: no-treatment control group with the same schedule Testing: influence of testing that may impact subsequent performance (i.e., pre-test influences post-test). Tran and Lee (2014): Even though there was filler, it is possible that pre-test items cued the participants to the topic of micro-aggressions; comparison groups would help detect this In other research: expats in my longitudinal study show increase in sociocultural adaptation  because over the 5 waves, they are cued to its importance Commonly occurs in: designs with a pre-test Remedy: no-treatment control group with the same schedule would allow its measurement; a Solomon 4-square (where a treatment and non-treatment group does not get a pre-test would provide even greater control). Group Assignment Pre-test observation Manipulation Post-test observation High racial loading Random Evaluation, Perceived Acceptance, Enjoyable, Similar Yes: Nice talking to you. You speak English well for an Asian. Evaluation, Perceived acceptance, Enjoyable, Similar, Accuracy, Additional talk time Control Random Evaluation, Perceived Acceptance, Enjoyable, Similar Yes: Nice talking to you. Evaluation, perceived acceptance, Enjoyable, Similar, Accuracy, Additional talk time High racial loading Random none Yes: Nice talking to you. You speak English well for an Asian. Evaluation, Perceived acceptance, Enjoyable, Similar, Accuracy, Additional talk time Control Random none Yes: Nice talking to you. Evaluation, perceived acceptance, Enjoyable, Similar, Accuracy, Additional talk time Instrumentation: changes in the measuring instrument or measurement procedures over time. Tran and Lee (2014): NA. In other research: Research team members are categorizing counselor utterances (e.g., open-ended questions, closed-ended questions, reframes, restatements, challenges) and the meanings/definitions of these shift over time. Commonly occurs in: Designs with human raters Remedy: standardized measures, automated scoring devices, manipulation checks, strict standardized procedures, assessing inter-rater reliability Statistical Regression toward the mean: the tendency for extreme scores on any measure to revert (or regress) toward the mean of a distribution at re-administration. Tran and Lee (2014): If there had been an immediate national news story related to racism toward Asian Americans related to COVID-19 and the study occurred in that day (but then the post-test would have needed to be spaced further out). In other research: Parental stress is extremely high when the parent enrolls in a parenting class and it is less high at the next measurement Commonly occurs in: Designs where research participants are enrolled when they present for services Remedy: random assignment to treatment; no-treatment control groups Spontaneous remission: the tendency for medical and psychological problems to improve over time without any form of treatment Tran and Lee (2014): difficult to imagine In other research: the presence of depression symptoms that are not present six months later Commonly occurs in: Designs where research participants are enrolled when they are patients who present for services Remedy: random assignment to treatment &amp; no-treatment control groups 4.5 Experimental Designs Research can achieve the state of experimental when The analysis seeks to determine whether changes in the independent variable (IV, a factor or predictor variable with two or more conditions/levels) lead to change in the dependent variable (DV, outcome variable); To rule out potential confounds and plausible rival hypotheses, there is maximum control over extraneous variables/noise; this control might be achieved through Inclusion/exclusion criteria, Manualized protocols, Standardization of context/setting. The IV/factor is systematically manipulated; comparing two groups of people who differ on the IV is not an experiment (see Jhangiani et al.s (2019) chapter on non-equivalent group designs); Random assignment to the conditions. This is the gold standard; without random assignment there is no experiment. A random clinical trial involves random assignment to treatment and control conditions, Causality is often better established when the control condition offers a placebo (a believed-to-be inert condition that looks like the treatment condition). Placebos often work! Just for fun (optional) see WNYCs Radiolab story on Placebo and Hidden Brains episode, All the Worlds a Stage  Including the Doctors Office For ethical and practical reasons (i.e., the researchers believe the treatment is effective and wish it to be given to many), there can be a wait-list control condition. Within this broad category of a variety of designs consider the following: 4.5.1 Between-Subject Experiments Each person is randomly assigned and tested in only one condition. This would have been the case for Tran and Lee (2014), had there not been a pre-test observation. Group Assignment Manipulation Post-test observation Low racial loading Random Yes: Nice talking to you. You speak English well. Evaluation, Perceived acceptance, Enjoyable, Similar, Accuracy, Additional talk time High racial loading Random Yes: Nice talking to you. You speak English well for an Asian. Evaluation, perceived acceptance, Enjoyable, Similar, Accuracy, Additional talk time Control Random Yes: Nice talking to you. Evaluation, perceived acceptance, Enjoyable, Similar, Accuracy, Additional talk time Random assignment protocols can be achieved in a variety of programs including R and randomizer.org. Random assignment is often determined one participant at a time (i.e., simple random assignment where each person has an equal chance of being randomly assigned to any of the groups). When there is strict need for balanced designs (equal cell/group sizes), a block randomization protocol can be specified (i.e., all conditions occur once in the sequence before any of them is repeated; then they all occur again before any is repeated). Within each of these blocks the conditions occur in a random order. For example, if Tran and Lee had used a block randomization, the first nine assignments might have looked like this: Participant Condition 1 Low 2 High 3 Control 4 High 5 Low 6 Control 7 Control 8 Low 9 High Matched groups is an variant of simple random assignment. Here, participants are ranked on some variable the researcher wishes to control. If Tran and Lee believed that internalized racism would impact the outcomes, the participants could take a pre-test of internalized racism. Participants could be placed in rank order of score. The highest three would be randomly assigned to the three conditions; then the next highest three and so forth. 4.5.2 Within-Subject Experiments In a within-subjects experiment each participant is tested under all conditions. We can imagine the Tran and Lee (2014) circumstance  perhaps the participant shows up to Psych 101 experiments 3 weeks in a row and, each time, is somehow exposed to the high racial loading, low-racial loading, and control conditions (wed need to be a little creative so it wouldnt be obvious). An advantage of any within-subjects/repeated measures experiment is that it provides maximum control of extraneous participant variables (e.g., the participants all have the same SES, IQ, contextual variables). Order effects are a big consideration in within-subjects experiments. Order effects occur when participants responses are affected by the order of conditions. Still, Carryover effects could occur, in that the effect of the first experienced condition might impact outcomes in the next condition (e.g., the Tran and Lee participant experiences the high racial loading first and is more cautious at follow up; or withdraws from the study). Practice effects occur when there is improved performance over time  owing to practice. Fatigue effects occur when there is deteriorating performance from tiredness or boredom. Context or contrast effects occur when knowledge or experiences in a prior trial provide a contrast/context for responses in the next trial. In Tran and Lee (as with many repeated measures experimental designs), we would want to counterbalance the order such that the order is randomly determined. In complete counterbalancing, an equal number of participants complete each possible of order of conditions. Counterbalancing has two primary effects: Controls the order of conditions so that it is no longer a confounding variable If there are carryover effects, it is possible to detect them (e.g., analyzing the data separately for each order to see whether it had an effect). Hypothetical Tran and Lee (2014), within-subjects, counterbalanced ID Pre-test Manip #1 Measures#2 Manip #2 Measures#3 Manip #3 Measures #4 1 yes High yes Low yes Control yes 2 yes Low yes Control yes High yes 3 yes Control yes High yes Low yes When I teach ANOVA, we progress through a series of ANOVA designs that correspond with the following research designs: Research Design Corresponding ANOVA Post-only (or single time point) group design One-way ANOVA Increasing control over an extraneous variable by including it as a covariate ANCOVA (analysis of covariance) Factorial design (between subjects) Factorial (between-subjects) ANOVA Pre-post group design One-way repeated measures ANOVA Pre/post factorial design (the classic RCT model) Mixed design ANOVA 4.6 The Validity Family Earlier in the lecture, we reviewed six common threats to internal validity that were common to research designs that lacked pretty basic things: pre-test, random assignment, comparison groups. However, validity threats apply to all research designs. Internal validity: whether the evidence of a study supports the existence of a causal relationship among its variables. KEYWORD: CAUSALITY External validity: whether the proposed relationship generalizes beyond characteristics of the study in which it was found. KEYWORD: GENERALIZATION Construct validity: whether the interpretation of the causal relationship is accurate. KEYWORD: MEANING (Statistical conclusion validity: whether the facets of the quantitative evaluation were appropriate. Test/psychometric validity: whether or not a particular measurement or observation measures what it purports to measure (much, much, more in psychometrics). 4.6.1 Defining Internal Validity 4.6.1.1 Threats to Internal Validity The purpose of an experiment is to show that two variables are statistically related and to do so in a way that supports the conclusion that the independent variable caused any observed differences in the dependent variable. Youve likely heard correlation does not imply causation  thus in order to infer causality (we never ever ever prove), we must design our study in such a way that we rule out plausible rival hypotheses. When we do, our study is high in internal validity. That is, the way the research was conducted supports the conclusion that the IV caused observable differences in the DV. Kazdins (2017) text identified a number of factors (outside of experimental design) that threaten internal validity: Selection Bias: systematic differences in groups based upon the selection or assignment of subjects to experimental conditions. Remedy: random selection from the population; random assignment to groups; using difference tests on key variables (preliminary analyses) Diffusion or Imitation of Treatment: the intervention given to one group may be provided accidentally to all or some subjects in the control group as well. *Remedy: manipulation checks Special Treatment or Reactions of Controls: in an investigation where the intervention, treatment, or program is administered to the experimental group, the no-treatment control group may also be accorded special attention, and thus react in unexpected ways. The Third Variable Problem: two variables are correlated with each other because both are correlates of a third factor, even when there is no direct or indirect causal relationship between the first two (Brewer, 2000). Here, the relationship between X and C is not causal Because X and C are correlated, the changes in Y could be misattributed to X when they are actually caused by C Thus, there is spurious correlation between X &gt; Y Illustration of the third variable problem Therefore, we should ask, Do we have hidden variables? Remedy: random assignment; also when covariates are identified, test for moderating or mediating effects Illustration of the third variable as moderating or mediating Attrition or Experimental Mortality: subjects dropping out of the experiment over time, particularly when there is a differential loss of subjects between groups. *Remedy: know your pop/lit, start huge, do everything you can to keep your participants (within ethical limitations) Boggs et al. (2005) examined outcomes of Parent-Child Interaction Therapy (PCIT) participants on the basis of their completion status (i.e., if they dropped out of treatment) one and three years later. The narration of the article makes clear the problem of attrition in (a) the original study, (b) the follow-up study, and (c) treatment in general (hence they wanted to study the effect of attrition)! So what to do about attrition: Everything you can afford (and do not involve coercion) 0to minimize it Incentives Increasing incentives for longitudinal Pay participants (consider something equivalent to minimum wage) Address it in the statistical analysis. West et al. (2000)(pp. 50-51) had a complete data set (simulated) where half of the participants were assigned to control and treatment conditions. The estimated true difference was .5. The data was further simulated to assign some of the cases to be missing. Knowing the true difference, the researchers analyzed the data with three different approaches to managing the missingness. Typical analysis Toss out all participants in treatment group who do not receive treatment. This results in a biased estimate of causal effect; direction of bias is unknown. Using the typical analysis, the difference was estimated to be 1.045. Intention to treat analysis Compare mean response of all participants assigned to treatment condition (regardless of whether they received treatment) with mean response of those in control condition. The intent-to-treat difference was estimated to be .34. CACE (complier average causal effect) analysis Create an unbiased estimate of treatment effect for those who receive treatment. It is a complicated statistic  but the estimate is .5. If you have access to the West et al. (2000) chapter, it is worth looking at the table where this is demonstrated. In other lessons in the OER I offer additional approaches (i.e., multiple imputation, available item analysis) to managing missing data. It happened to us! Below are graphs from Scott Campanarios doctoral dissertation (S. Campanario, 2018; S. C. Campanario et al., 2020)  a random clinical trial evaluating three versions of SPUs Online Field Guide. Control  adjust to college only activities Traditional  Control + traditional career planning activities Calling  Traditional + Control + Ignatian discernment activities Demonstration of problems caused by attrition Attrition from pre (T1) to post (T2) as high. The graph on the left uses listwise/pairwise deletion (lose the whole case) if pre or post was missing. We expected that randomization would cause the three TA starting spots to be closer  but they were not! Why not? We arent exactly sure, but its likely that the students who persisted in the calling condition (the most demanding), were those who started higher on the outcome in the first place (career decision-making self-efficacy and purpose). When we used multiple imputation to preserve case with missingness, it brought the means of the pre-test closer together and reflected our hypotheses (and likely the true state of the data) better. JUST TO BE CLEAR  you can never really know the bias introduced by missingness  but this is a story emphasizing why it is important to minimize it. ** One more Threat to Internal Validity ** Combination of Selection &amp; Other Threats: selection of groups that are already formed prior to the experiment might lead to a combined confound of selection and some other threat to internal validity. The experience of one of the groups in the study (e.g., history, maturation) may differ systematically from the other group. The differential influence of this threat among groups is referred to as an interaction with selection. Remedy: random assignment to treatment groups 4.6.2 A Bit about the Remedies Random selection: Drawing subjects from a population in such a way that each member of the population has an equal probability of being drawn. Random assignment: Allocating or assigning subjects to groups in such a way that the probability of each subject appearing in any of the groups is equal. This is usually accomplished by determining the group to which each subject is assigned by a table of random numbers (or now, on R or randomizer.org). Comparison of Tx and control groups is only legitimate when the Tx and Control groups are equivalent in terms of all important background characteristics at pre-test. Random assignment normally absolves concerns about this assumption. 4.6.3 Strategies or Equating Non-Equivalent Groups Identify all important covariates; attempt to discern hidden variables. Measure each of these covariates with perfect reliability (or statistically adjust for imperfection). Specify a correct linear relationship b/t the pretest variables and outcome variable. Demonstrate that pretest maturation rates do not differ in the Tx and Control groups. (Group * Pretest interactions are bad). When each of these strategies has been successfully completed, the researcher has strong ignorability (this is good; but achieving it is extraordinarily difficult and fraught with uncertainty). To offer a change from the lecture/chapter format, match the definition to the type (term) of control group. A Matching Exercise (answers provided at the end of the lesson) Term Definition a. Control Group ___A group that does not (ever) receive the experimental condition or intervention. b. Patched-up Control Group ___A control condition designed to ensure that groups are equal with respect to potentially important but conceptually and procedurally irrelevant variables. Groups are equalized with regard to a particular variable(s) c. Yoked-control Group ___Experimental condition/intervention that is not provided during the period that experimental subjects receive the intervention d. Wait-list Control Group ___A group that is not randomly composed from the pool of subjects in the study. While its intent is to address some issues of internal validty, its composition is derived from issues of convenience. e. No-treatment Control Group ___Experimental condition or intervention is not provided during the period that experimental subjects receive the intervention. After this period, subjects in this group receive the intervention. 4.7 Defining External Validity The generalizability of the causal findings; can the same cause-effect relationship be obtained across different subjects, settings, methods. Three questions: Robustness: Can it be replicated in the face of variations of subject populations and settings (Milgrams 1963 move from Yale lab to a seedy office) Ecological validity: Is it representative of what happens in everyday life? Findings obtained with college students are interesting, but have no ecological validity until they have been demonstrated to occur in more representative circumstances. Relevance: Does it matter? Akin to ecological validity  is the finding related to events or phenomena that actually occur in the world? Are the results useful or applicable to solving problems and improving quality of life? 4.7.1 Threats to External Validty Sample characteristics: The extent to which results be generalized to other persons who vary in age, race, ethnic background, education, etc. Stimulus characteristics: The extent to which results can be extended across stimulus characteristics (i.e., features of the study) of the experiment. Contextual Characteristics: Reactivity of experimental arrangements: the influence of the subjects awareness that they are participating in an investigation. Multiple-treatment interference: Drawing conclusions about a given treatment when it is evaluated in the context of other treatments. Novelty effects: effects of an intervention may, in part, depend upon their innovativeness or novelty. Assessment Characteristics: Reactivity of assessment: simply because subjects are aware that they are being assessed, they may alter their performance. Test sensitization: in designs where pre and posttest measures are completed, the pretest may sensitize the participants so that they are affected differently by the intervention (i.e., pretest sensitization). Time of measurement and treatment effects: the possibility that the effects of the experiment are demonstrated at the time of the testing, but might not generalize to a later point of time. 4.7.1.1 Re-Enter Parsimony and Plausibility Plausibility: an interpretation of the results of an investigation on the basis of some other influence than the one the investigator has studied or wishes to discuss. Parsimony: directs us to select the simplest version or account of the data among the alternatives that are available. 4.8 Balancing Internal and External Validity As a general rule, design features that make an experiment more sensitive as a test of the independent and dependent variables tend to limit the generality of the findings. Conversely, features of an experiment that enhance generality of the results tend to increase variability and to decrease the sensitivity of the experimental test ((2017), p. 79) Writing in the American Psychologist in the 1980s, Mooks (1983) statement emphasizes the importance of careful research design: I am afraid there is no alternative to thinking through, case by case, (a) what conclusion we want to draw and (b) whether the specifics of our sample or setting will prevent us from drawing it. (386) 4.8.1 The Bubble Hypothesis Gelso (1979) used bubble hypothesis as analogy for balancing internal and external validity. Gelso described the difficulty which arises when someone attempts to place a decal on a window and a bubble appears. When the bubble is depressed in one area, it arises somewhere else. The metaphor back to internal and external validity includes: Inevitable trade-offs exist at all stages of research. Knowledge is most powerfully advanced through the use of a variety of methods. Rigor vs. relevance Rigor: internal validity Relevance: external validity Key points in the balancing of internal and external validity have been made by the following scholars: As a priority internal validity is usually regarded as more important than, or at least logically prior in importance to external validity (Kazdin, 2017). Some of the best and most helpful research begins with understanding the phenomena of interest, and studies with that focus may have very little external validity (Mook, 1983). Rarely can internal, external, (and construct) validity be properly addressed within the context of a single research designthey require systematic, programmatic research studies that address a particular research question across different operations and research settings (Brewer, 2000). 4.9 Defining Construct Validity The extent to which a causal relationship could be generalized from the particular methods and operations of a specific study to the theoretical constructs and processes they are purported to represent. Construct1 &gt; Operations &gt; Construct2 Specific operations/measures are merely partial representations of the theoretical constructs of interests (Brewer, 2000). 4.9.1 Threats to Construct Validity Unknown range problem: the failure to specify precisely what levels of the IV are expected to be causally significant; and over what range of outcomes Unknown range of stimulus variation Unknown range of measurement Because of these problems, it is difficult to determine whether a failure to confirm a predicted relationship is a failure of theory or a failure of operation. Attention and contact with the clients: the intervention may have exerted its influence because of the attention provided rather than because of special characteristics unique to the intervention. Single Operations and Narrow Stimulus Sampling: occurs when one cannot discern the construct of interest (i.e., treatment or types of description of treatment) from the conditions of its delivery (i.e., therapist or case vignette). Experimenter Expectancies: the threat that expectancies, beliefs, and desires about the results on the part of the experimenter influences how the subjects perform; unintentional expectancy effects. Cues of the Experimental Situation: seemingly ancillary factors associated with the intervention that may contribute to the results; demand characteristics of the experimental situation. 4.10 Statistical Conclusion Validity Defined as: those facets of the quantitative evaluation that influence the conclusions we reach about the experimental condition and its effect. 4.10.1 Threats to Statistical Conclusion Validity Low Statistical Power: the failure to reject the null hypothesis when it is false. Variability in the Procedures: if variability is minimized, the likelihood of detecting a true difference between the treatments or treatment conditions and control conditions is increased. Subject Heterogeneity: the greater the heterogeneity or diversity of subject characteristics, the less likelihood there will be to detect a difference between alternative conditions. Unreliability of Measures: the extent to which the measures assess the characteristics of interest in a consistent fashion. Multiple Comparisons and Error Rates: The more statistical tests that are performed, the more likely a chance difference will be found, even if there are no true differences between conditions (Type I error). Also called family-wise error, experiment wise-error. Throughout the statistical portions of the ReCentering Psych Stats OER, I will consistently attend to statistical conclusion validity by attending to power analysis, statistical assumptions (and their violation/nonviolation), effect sizes, confidence intervals. In sum  we look at the dashboard of metrics we learn from and about our analyses. 4.11 Answer Key Answers to the exercise matching the terms to the definitions of control groups e, c, a, b, d References "],["SingleCase.html", "Chapter 5 The Case Study and Single Case Design 5.1 Navigating this Lesson 5.2 The Anecdotal and Uncontrolled Case Study 5.3 Single Case Designs 5.4 Experimental Design Strategies 5.5 The Big Debate: Evaluating Data in Single-Case Designs 5.6 Case-Based Time-Series Analysis 5.7 Incorporating Systematic Evaluation into Clinical Practice 5.8 From the Perspective of Philosophy of Science", " Chapter 5 The Case Study and Single Case Design Screencasted Lecture Link This lesson provides an overview of the case study approach to research ranging from the anecdotal/uncontrolled case study to experimentation in N of 1 studies. We also spend a moment considering how we might integrate some of these methodologies in practice. 5.1 Navigating this Lesson There is about 45 minutes of lecture. 5.1.1 Learning Objectives Learning objectives from this lecture include the following: Evaluate N of 1 experiments with statistical criteria List strengths and weaknesses of single case designs Describe potential application of the N of 1 approach to practice Perspectives from philosophy of science 5.1.2 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Jhangiani et al. (2019): Overview of single-subject research (44), Single-subject research designs (45), The single-subject versus group debate (46); Borckardt, J. J., Nash, M. R., Murphy, M. D., Moore, M., Shaw, D., &amp; ONeil, P. (2008). Clinical practice as natural laboratory for psychotherapy research. American Psychologist, 63, 77-95. doi:10.1037/0003-066X.63.2.77 An example of a statistical advance in N of 1 approaches . Consider this to be an introduction to save in your backpocketyou wont have to do it while you are in grad school (but you could if you wanted to do an N of 1 research project or dissertation). 5.2 The Anecdotal and Uncontrolled Case Study Has a rich and deep place in history and offers a continuum between anecdotal and uncontrolled to true experiments. 5.2.1 Why Bother with the Anecdotal/Uncontrolled Case Study? source of hypotheses source for developing therapy/treatment techniques study of rare phenomena Consider the story of Phineas Gage As well as emerging opportunities for discovery providing a counter-instance for notions that are considered to be universally applicable selected systematically to prove a point (also a weakness) 5.2.2 Limitations of the (uncontrolled, anecdotal) Case Study self-report, anecdotal nature questions objectivity threats to internal validity history, maturation, testing, instrumentation, statistical regression, selection biases, attrition, combo, diffusion or imitation of treatment threats to external validity absence of standard or replicable procedures. 5.3 Single Case Designs As true experiments, single-case designs can demonstrate causal relations and can rule out or make implausible threats to validity with the same elegance of group research (Kazdin, 2017, p. 273). Three elements to the single case experiment: Continuous Assessment: Observations on multiple occasions over time prior to and during the period in which the intervention is administered. a distinguishing difference between group (between-group) and single-case research. In the between-group research, there is usually a pre- and post- test given to a treatment and control group. provides several observations over time to allow the comparisons of interest. Baseline Assessment: Assessment for a period of time prior to implementation of the intervention. allows descriptive (provides info about the extent of the clients problem) and predictive (serves as basis for establishing predictions for performance) functions. Continuous Assessment: Observations on multiple occasions over time prior to and during the period in which the intervention is administered. a distinguishing difference between group (between-group) and single-case research. In the between-group research, there is usually a pre- and post- test given to a treatment and control group. provides several observations over time to allow the comparisons of interest. 5.4 Experimental Design Strategies 5.4.1 ABAB Designs A family of experimental arrangements in which continuous observations of performance are made over time for a given client (or group of clients). Over the course of the investigation, changes are made in the experimental conditions to which the client is exposed. sometimes termed a reversal design because the phases are reversed to demonstrate the effect of the program. causality is demonstrated by showing that the behavior reverts to or approaches the original baseline after the intervention is withdrawn or altered (during the second A phase). no reversal, no causality ethical issues: Do we withdraw a treatment thats working well? Do we really shout for joy when withdrawal of the treatment results in deterioration of behavior? 5.4.2 Multiple Baseline Designs Demonstrates the effectiveness of an intervention by showing that the behavior change accompanies introduction of the intervention at different points in time. That is, once the intervention is presented, it need not be withdrawn or altered to reverse behavior to or near baseline levels. Thus, the clinical utility of the design is not limited by the problems of reverting behavior to pretreatment levels. Key feature: evaluation of change across different baselines. The intervention is introduced to the different baselines at different points in time. Ideally, change occurs when the intervention is introduced in sequence to each of the baselines. Each behavior is observed and graphed separately. Many versions: Sometimes baselines may represent different behaviors, individuals, situations. Ideally behaviors still exposed to the baseline condition do not change until the intervention is applied. If they do, it suggests that the intervention may not have been responsible for change. Rather, extraneous factors (history, testing) may have led to the change. Sometimes there are generalized effects; not ideal. 5.4.3 Changing-Criteria Designs Demonstrates the effect of an intervention by showing that behavior changes in increments to match a performance criterion. A causal relation between an intervention and behavior is demonstrated if behavior matches a constantly changing criterion for performance over the course of treatment. Once performance consistently meets the criterion, the criterion is made more stringent. The effect of the intervention is demonstrated if behavior matches a criterion as the criterion is changed. Kazdin writes that the changing-criterion design is less powerful because the effects of extraneous events could account for a general increase or decrease in behavior. If the researcher can show a unilateral change in behavior over time, causality is better supported. 5.5 The Big Debate: Evaluating Data in Single-Case Designs Visual Inspection Statistical Evaluation (traditional) preference of n = 1 investigators available seems sacrilegious to many provides greater assurance of objectivity (at least on the face of it) more consistent with the clinical picture Kazdins text identified four criteria for evaluating the single-case design (2017). Criteria for Data Evaluation in Single-Case Designs Changes in means (averages) The mean rate of the behavior shows a change from phase to phase in the expected direction. Change in level When one phase changes to another, a level refers to the change in behavior from the last day of one phase (baseline) and the first day of the next phase (intervention). An abrupt shift facilitates data interpretation. Change in slope (trend) The speed with which change occurs once the conditions are changed (baseline to intervention, intervention back to baseline). Latency of change The speed with which change occurs once the conditions are changed (baseline to intervention, intervention back to baseline). 5.5.1 Evaluating Single Case Study Designs The lecture reviews a series of graphs and describes how they connect back to the criteria. Owing to concerns of including copyrighted material in this printed copy, I am omitting those from this portion of the lesson. These, though, are the notesthat go with each of the examples: In the weight loss example (a graph showing a steady deline of weight over 5 weeks): Data is objective Not continuous Stability of problem not demonstrated with abaseline period of observation Lacks multiple cases Cannot rule out: history, maturation, testing, instrumentation, statistical regression toward the mean. In the flatulent thoughts example, there is a period of baseline characterized by 12-21 thoughts per day with a good deal of variability. Once treatment starts, there is a variable progression downard. There is a break and then follow up observation where the thoughts remain low (5-7 a day). Data is objective Continuous observation Stability of problem is demonstrated Immediate and marked effects demonstrated Lacks multiple cases Cannot rule out: history, maturation Good controls for testing, instrumentation, statistical regression toward the mean In the agoraphobia example there is a period of baseline where there was no actiity spent outside the house. There is a period of intervention where there is a substantial increase. Then aperiod of two-month followup with increased activy and agreat deal of variability. Then 18-months follow-up. Data is objective Continuous observation Stability of problem demonstrated Lacks multiple cases Cannot rule out: history, maturation, Controls for testing, instrumentation, statistical regression toward the mean. In the bedwetting example there is pretraining during the baseline period. There is an substantial and immediate drop in level when trainng begins and continued success that follows. Data is objective Continuous observation Stability of problem demonstrated Contains multiple cases Controls for history, maturation, testing, instrumentation, statistical regression toward the mean 5.6 Case-Based Time-Series Analysis the practitioner-generated case-based time-series design with baseline measurement fully qualifies as a true experiment and that it ought to stand alongside the more common group designs (e.g., RCT) as a viable approach to expanding our knowledge about whether, how, and for whom psychotherapy works. (Borckardt et al., 2008, p. 77). 5.6.1 The Trouble with Interpreting N = 1 Neither visual inspection nor conventional statistics are to be relied on for analyzing single-patient time-series studies (p. 82). The problem: auto-correlation Observations are auto-correlated if the value of one observation depends (at least in part) on the value of one or more of the immediately preceding observations. Simulation-modeling analysis (SMA) as a technique for analyzing N = 1, time-series data Borckardt et al. (2008) provided an example of pain intervention. Please refer to the tables and figures in the Borckardt et al. article. Use Pearson r to calculate the Lag 1 autocorrelation. Result for baseline &amp; treatment: r = .85. A Lag 1 correlation is the degree to which an observation at Time K predicts the observation that comes immediately after it (at Time K + 1). The Lag 1 correlation is simply the correlation between each data point and the point immediately following it. The research question: Is the decrease in pain from baseline (M = 7.78) through tx (M = 3.29) statistically significant? SMA says yes: r (44) = -.69, p = .049, even after controlling for autocorrelation. SMA answers the question, mere random variation of pain reports is an unlikely explanation of the phase difference from baseline to treatment, EVEN AFTER controlling for autocorrelation (that is, even after autocorrelation, there is systematic variation in the data and we will attribute it to our intervention). Another example: What would behavioral activation theory suggest about the relationship between mood and social engagement? Cross-lagged correlations can be used to determine the direction of change. In this case, does change in mood precede behavioral activation, or vice versa? The article includes three examples, an instructional appendix, and a link to free SMA software. 5.7 Incorporating Systematic Evaluation into Clinical Practice Assess and establish treatment goals(Morgan &amp; Morgan, 2001) Clear, specific, explicit. Specify and assess procedures and processes Name the means and processes that are expected to lead to therapeutic change. Select credible measures Identify or develop instruments, scales, measures. Regular, continuous, ongoing assessment Any concerns from internal/external threats to validity? Testing effects? Not an issue if they are part-n-parcel to treatment. Evaluate data/outcomes Maybe SHARE it with client. Linda McDaniels example of the Parent Trust client who was so excited to rate herself at the next level. 5.7.1 Kazdins (2017) Gloria Case Kazdin retells the case of clinical that asked clients to self-assess at each visit. Kazdins text had three graphs  two of established measures and a third of the G-scale, which represented Glorias self-rating of progress. A copy of the scale is shown in the lecture and available in Kazdins text. Consider these questions: How did the Clinician attempt to systematic ally evaluate the Clinical Practice? How are evaluation/methods issues similar/different to clinical/case conceptualization issues. How credible is the G scale? Can you imagine doing this in YOUR practice? With what types of clients/circumstances might this work or not work? Looking at Figure 11.5, what can you say about means, level, slope, and latency of change? 5.8 From the Perspective of Philosophy of Science Morgan and Morgan (2001) addressed the push and pull between statistical/group designs and the single case design. Role of variability is the key. Variability is an irreducible property of natural phenomena (Gould 1996). Empirical statistical studies seek to neutralize variance. We owe this to Plato who saw variation as accidental; ideals lived on a higher plane. N = 1 studies exploit variability, to provide pivotal information about the impact of the IV over time. We owe this to Darwins grand unification theory (genetic variation serves as the raw materials on which selective pressures can operate over time). \"It is difficult to envision a clinical application, at least within psychology, medicine, or other service oriented disciplines, for which the purported goal is the alteration of group means. (2001), p. 123]. References "],["Qualitative.html", "Chapter 6 Quick Qualitative Introduction 6.1 Navigating this Lesson 6.2 The Qual v Quant Contrast 6.3 From Whence we Came 6.4 Critical Qualitative Foundation 6.5 Establishing the Credibility of a Qualitaive Study: Trustworthiness 6.6 EXAMPLE: Adjustment of the Female, Expatriate Spouse  A longitudinal investigation (Bikos, Çiftçi, Güneri, Demir, Sümer, Danielson, DeVries, et al., 2007) 6.7 Naturalistic Inquiry Methods 6.8 Establishing Trustworthiness 6.9 How Would I Select a Qualitative Method for my Dissertation?", " Chapter 6 Quick Qualitative Introduction Screencasted Lecture Link Qualitative research methods is a huge topic. There are a number of different approaches (that span an array of philosophies of science) and so is impossible to address properly in an hour-long review. In this short time, we will start with a bit of qualitative history that applies directly to pscyhology. I will demonstrate one qualitative method  Naturalistic Inquiry (which was an early method whose ideas are reflected in other approaches) in a study I led a few years ago. 6.1 Navigating this Lesson There is about 1 hour of lecture. 6.1.1 Learning Objectives Learning objectives from this lecture include the following: Contrast key elements of qualitative and quantitative research methods. Distinguish between a priori and grounded theory. Identify criteria that lead to the trustworthiness of a qualitative study. 6.1.2 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Jhangiani, R. S., Chiang, I.-C. A., Cuttler, C., &amp; Leighton, D. C. (2019). Research Methods in Psychology. https://doi.org/10.17605/OSF.IO/HF7DQ Chapter VI: Qualitative research (31) Observational research (32) Bikos, L. H., Çiftçi, A., Güneri, O. Y., Demir, C. E., Sümer, Z. H., Danielson, S., DeVries, S., &amp; Bilgen, W. (2007). A longitudinal, Naturalistic Inquiry of the adaptation experiences of the female expatriate spouse living in Turkey. Journal of Career Development, 34, 28-58zq. In this study, we used the qualitative method, Naturalistic Inquiry (Lincoln &amp; Guba, 1985; Erlandson, Harris, &amp; Skipper, 1993). As you read, note the theoretical foundation for launching the project. Read heavily the method, making particular note of what makes this study trustworthy. The ms is long. Im more interested in you making mental (and marginal) notes about design issues and less interested in you knowing the outcomes of the study. Take a quick look at the Results/Discussion. Here, Im more interested in you taking note of the style of writing and the integration with the literature. In class Ill share all the behind-the-scenes stories. 6.2 The Qual v Quant Contrast When I include a qualitative lecture in the context of a research design class, the qualitative component becomes inevitably contrasted with the quantitative background. As one who conducts (and values) the contributions of qualitative, this is not at all to diminish its contributions. Quantitative Qualitative Philosophy of science is positivist to post-positivist Philosophy of science is somewhere else: postpositivistic, constructivist-interpretivist, naturalistic, critical-idiological Laboratory, controlled setting. Natural setting. Use of valid and reliable scales and instruments. Human instrument. Use of implicit knowledge. Use of tacit knowledge. Sampling methods are typically random or representative. Sampling methods are purposive. Deductive data analysis: explanation guides the development of the study. Inductive data analysis: explanation grows out of the data. A priori theory. Grounded theory. Research design is predetermined. Research design is emergent. Experimenter determined outcomes. Negotiated outcomes. Scientific and technical reporting. Case study reporting mode. Concerned with generalization of results. Idiographic interpretation of data. Credibility determined by internal and external validity, reliability, objectivity. Trustworthiness of the results established by other criteria such as an audit trail. 6.3 From Whence we Came Qualitative research methods have long and historied rootes. I was originally trained in the Lincoln, Guba, and Denzin tradition of naturalistic inquiry. Image of bookcovers of qualitative research handbooks that have guided the methodology Dr. Norman K. Denzin is Distinguished Professor of Communications, College of Communications Scholar, and Research Professor of Communications, Sociology, and Humanities at the University of Illinois, Urbana-Champaign. He has described himself as an ethnographer, an interpretive interactionist, a cultural critic, and an occasional social theorist. Dr. Yvonna S. Lincoln is a Professor in the Department of Educational Administration at Texas A&amp;M University. She has been with the institution since 1991. Prior to that time, Dr. Lincoln held teaching positions at the University of Kansas and Vanderbilt University. Dr. Egon G. Guba, retired, Professor Emeritus in Education, University of Indiana-Bloomington. You can see that these individuals are from education and disciplinary communications. As we get closer to psychology, there have been several important publications that have influenced our processes. In an editorial in the Academy of Management Journal, Gephart (2004) provided some guidelines for those conducting qualitative research in Industrial-Organizational psychology. As a one who reviews a number of qualitative methods, I agree with these and have added one additional guidelines: one off  embedded in a larger research program? Adequate lit review? Explicit statement of goals, objectives, research questions? Clear &amp; thorough construct definition? Sufficiently specified methodology? Narrative thread evident in discussion/conclusion? Plus (mine): A clear location in philosophy of science that drives the method? 6.4 Critical Qualitative Foundation 6.4.1 The Qulitative Orientation Phenomenological, -emic Seeking to understand the phenomenon from a position on the inside Inductive Constructing meaning from heterogeneous data Emergent design How comfortable will your dissertation committee be (&amp; IRB) if you dont precisely specify all of your method? 6.4.2 Methods of Observation: Role of the observer Covert participant observation Concealed observation Unconcealed participant observation Nonparticipant observation 6.4.3 Gathering and Analyzing Data Informant selection: purposive, stakeholders Analytic induction Grounded (vs. apriori) theory Constant comparison Gather/analyze until saturation Negative case analysis (i.e., a different utilization of outliers) 6.4.4 Data Collection Field notes and logs Memos/reflexive journal Documents Artifacts Triangulation 6.4.5 Data Analysis Unitizing data Coding Emergent category/designation Negative case analysis 6.5 Establishing the Credibility of a Qualitaive Study: Trustworthiness Although the history (as documented in some of the Handbooks noted earlier) has moved away from directly comparing qualitative and quantitative approaches, I still find this adapted from Lincoln and Gubas Naturalistic Inquiry (1985) to be useful in framing the differences. Criterion Conventional Term Naturalistic (Qualitative) Term) Naturalistic (Qualitative) Techniques Truth value Internal validity Credibility Prolonged engagement, Persistent observation, Triangulation, Referential adequacy, Peer debriefing, Member checks, Reflexive journal Applicability External validity Transferability Thick descriptions, Purposive sampling, Reflexive journal Consistency Reliability Dependability Dependability audit, Reflexive journal Objectivity Confirmability Confirmability audit, Reflexive journal 6.6 EXAMPLE: Adjustment of the Female, Expatriate Spouse  A longitudinal investigation (Bikos, Çiftçi, Güneri, Demir, Sümer, Danielson, DeVries, et al., 2007) 6.6.1 Beginnings of the Project Below is a sketch of the culture shock model that is often used to prepare individuals for study, work, and relocation abroad. My husband and I were exposed to this model in pre-departure preparation for our expatriation. Curious about it, I began a longitudinal (5 waves across 1 year) examination of the first-year adaptation of female, expatriate spouses, in Ankara, Turkey. A sketch of the culture shock model In this figure I have superimposed the struggles that my family faced: A sketch of the culture shock model superimposed with my personal experience As I describe in the lecture, the study was mixed methods. The participants (N = 32) completed measures and interviews at each of the waves. Our quantitative analyses suggested no predictable change over time. This was true for mental health, alcohol use, and marital satisfaction. A figure illustrating no predictable change in mental health over time A figure illustrating no predictable change in alcohol use A figure illustrating no predictable change in marital satisfaction over time 6.7 Naturalistic Inquiry Methods Lincoln and Guba (1985) and Erlandson, Harris, Skipper, and Allen (1993) Research Team Americans Team Members (n = 4) 1 held doctorate degree 3 held masters degrees in helping professions All were trailing, expatriate spouses Turkish Team Members (n = 4) 3 held doctorates and had lived abroad for extended periods (nine months or more) of time 1 held masters degree and was anticipating study abroad 6.8 Establishing Trustworthiness Individual member checks 24% of interviews. Persistent observation &amp; prolonged engagement 131 interviews, averaging 25 interviews per time-in-country stage Grand member-check offered to 32 stakeholders; 47% participated. Reflexive journal entries completed by research team at seven points in the project. Audit trail Confirmability audit completed by an external expert in qualitative methods. 6.8.1 Interviews 131 interviews between December 5, 2000 &amp; November 18, 2002 Interviews (and measures) completed within 2 week interval around each 3-month anniversary date 91 after September 11, 2001 Open-ended and informal Transcribed from notes taken with paper/pencil or laptop Examples items If you wrote a book, what big stories would you include? What things/people/events have helped your stay go more smoothly (more difficult)? What could your company have done (could do) differently? What changes have you noticed in yourself in the variety of roles and aspects of your life? After September 11, 2001: How have the terrorist attacks against the U.S. changed the way you think or feel about living in Turkey? 6.8.2 Data Analysis and Interpretation Interview elements unitized into the smallest complete thought. interviews for each stage ranged from 390 to 818 units Theming parties (2) held at the conclusion of each time-in-country interview stage. large sheets of newsprint, divided into 6 X 8 grids, teams separately categorized the units categorized data for each stage ranged from 30 to 55 themes Salient themes identified by frequency of cards in each theme common/overlapping themes between the two theming parties knowledge of the expatriate literature Case studies (5) completed at the end of each time-in-country stage. Grand Case Study Report (60 pages) integrated the five staged reports. Includes in-depth coverage of 13 major themes. 6.8.3 Reflexive Journal Entry Below is an example of a reflexive journal entry of one of the members of the team. Heres where research team members record their impressions, speculations, and experiences. It brackets researcher bias by acknowledging it. It is then part of the audit trail. An image of a reflexive journal entry 6.8.4 Interviewing Example: Unitizing Transcripts of the interviews are unitized into complete thoughts. These days, I use Microsoft Excel for the entire analysis process. ### Theming In this project we probably leaned a little positivist in that we had two teams who themed the data separately. These themes are captured in the spreadsheet. The spreadsheet also captures the participant ID number, the place in the transcript, and the wave (alphabetical). An image of a the units sorted by themes from the two teams. 6.8.5 The Case Study The case study captures the source of the data by identifying the participant number, wave letter, and place in the transcript. Because of the numerous participants and waves, we also used color-coded script to help in writing it up. ### Grand Member Check After the case study was drafted (not final, just drafted), we sent it to stakeholders (some of the research participants and others with a stake in the phenomena) to get their impressions. We asked, What sounds right? What did we miss? Is this true to your experience? We would have liked to have held these meetings in person, but due to the nature of repatriation, we asked for feedback in e-mail responses. ### Audit Trail and Audit Finally, we sent all of our materials to an expert in qualitative research methods who was aware of the study, but neither a research participant nor member of the research team. This individual examined our audit trail including interviews, documented processes, citations, and conclusions. This is an excerpt of their review. An image of feedback from the audit. 6.8.6 Evaluating Bikos et al. (2007) Strengths Curiosities The article clearly identified philosophy of science (constructivist-interpretivist) In practice, there was a great deal of post-positivist influence Clearly specified qualitative method (Naturalistic Inquiry) Atypically large # participants (8-15 is more common) and phenomenally huge # interviews. Clear specification of the credibility criteria and how they were implemented. Team analysis (NI allows for individual theming as well) 6.9 How Would I Select a Qualitative Method for my Dissertation? Use Gepharts criteria as a guide. Special qualitative issue in Journal of Counseling Psychology (2005 v.52, #2) devoted to most utilized qualitative methods. Its easier when the steps are clearly specified. Consensual Qualitative Research (Hill et al., 2005; Hill, 2012). Naturalistic Inquiry (Erlandson, 1993; Lincoln, 1985). Grounded theory (Fassinger, 2005). Less clear steps in broadly defined methods like phenomenology, ethnography Will your advisor/committee use a group? Group required: Consensual Qualitative Research No group required: Naturalistic Inquiry, Grounded Theory Should I use mixed methods? Im a big fan of mixed methods, but you dont have to do it all at once! At least in our program, one-half would be sufficient for the dissertation; you could collect both and save the other half for the subsequent publication. References "],["Psychometrix.html", "Chapter 7 Psychometrics Crash Course: A quick and dirty review of the primary elements of reliability and validity 7.1 Navigating this Lesson 7.2 Classical Test Theory 7.3 Traditional Estimates of Reliability 7.4 Defining Validity 7.5 Locating and Interpreting Reliability and Validity in Publications 7.6 Practice Problem 7.7 Answer Key", " Chapter 7 Psychometrics Crash Course: A quick and dirty review of the primary elements of reliability and validity Screencasted Lecture Link This lesson presume that you have not had a psychometrics course. In the particular research methods/statistics sequence I teach, psychometrics is the last in the series. This psychometrics primer is intended to demonstrate how to gather and interpret basic reliability and validity information. A lesson later in the ReCentering Psych Stats OER guides you through scoring your measures and conducting the basic psychometric evaluations (alpha coefficients). But first, a trivia question. Why is reliability abbreviated \\(r_{xx}\\) and validity abbreviated \\(r_{xy}\\)? The answer is at the end of the lesson. 7.1 Navigating this Lesson There is about 1 hour of lecture. 7.1.1 Learning Objectives Learning objectives from this lesson include the following: Memorize the true-score formula. Define reliability and validity (for memory), including Types of reliability Types of validity Retrieve and interpret reliability and validity information from published articles. Write an APA-style instrument entry. 7.1.2 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource. Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Jhangiani, R. S., Chiang, I.-C. A., Cuttler, C., &amp; Leighton, D. C. (2019). Research Methods in Psychology. https://doi.org/10.17605/OSF.IO/HF7DQ Chapter IV: Psychological Measurement Understanding psychological measurement Reliability and validity of measurement Practical strategies for psychological measurement 7.1.3 Planning for Practice At the end of the lesson I provide instructions for one of my favorite classroom assignments, the Penultimate Psychometric Template. In this, students find write-ups of 12 measures, mapping the parts-n-pieces of the write-ups, and then creating their own recipe/outline for how to draft descriptions of measures in future empirical papers. 7.2 Classical Test Theory Classical test theory (CTT) is based on Spearmans (1904) true-score model: an observed score is conceived of as consisting of two components  a true component and an error component \\(X = T + E\\) Where X = the fallible, observed score, obtained under ideal or perfect conditions of measurement (these conditions never exist) T = the true score, and E = random error. Measurement is the assignment of scores to individuals so that the scores represent some characteristic of the individuals (Jhangiani et al., 2019); measurement of psychological constructs is, psychometrics. While measurement does not require any specific instrument or process, there must be some systematic procedure for assigning scores so that they represent the characteristics of interest. Psychological constructs cannot be observed directly  they often represent tendencies to think, feel, or behave in certain ways and they often involve internal processes. Examples: intelligence, The Big Five, attitudes We can define constructs two ways: Conceptual definition: describes the behaviors and internal processes that make up that construct, along with how it relates to other variables. Operational definition: describes precisely how the construct is to be measured. Self-report: participants report their own thoughts, feelings, actions Behavioral measures: some aspect of participants behavior is observed and recorded. This could range from a highly structured lab task or a more natural setting. Physiological measures: involve recording any of a wide variety of physiological processes including heart rate/blood pressure, galvanic skin response, hormone levels, electrical activity, and blood flow in the brain. For any given construct/measures there can be a variety of operational definitions. Converging operations occurs when scores based on several different operational definitions are closely related to each other and produce similar patterns of results. This constitutes good evidence that the construct is being effectively measured. S. S. Stevens (1946) was among the first to suggest that the type of score assigned to individuals communicates more or less quantitative information about the variable of interest. He suggested four different levels of measurement. In the psychometric context it is critical that we know this measurement scale (a synomym). R recognizes at least 15 different types of data. Below I note the structure of the data you are most likely to see/use with each of the measurement scales (RPubs - R Intro Theory of Measurement, n.d.)(RPubs - R Intro Theory of Measurement, n.d.). Nominal (in R, factor): used for categorical variables and the scores are category labels; not considered to be quantitative. Ordinal (in R, integer [whole numbers, no decimal point]): assigning a score so that it represents the rank order of the individuals. Allows us to know if individuals are the same or different  and if who is higher or lower. One problem with ordinal scales is that we cannot presume the difference between two levels on an ordinal scale to be the same as the difference between two other levels (the equal interval problem). Interval (in R, integer or numeric): assigning scores using numerical scales in which intervals have the same interpretation throughout. In Fahrenheit or Celsius temperature scales, the difference between 30 and 40 degrees represents the same temperature difference as the difference between 80 and 90 degrees (each 10 degree interval has the same kinetic energy of molecules). One problem with interval scales is the absence of a true zero point. Therefore we cannot make statements like, X is twice as large as Y. Ratio (in R, numeric): has an equal interval scale plus a true zero point. Counts (e.g., cigarettes smoked, number of siblings, money) are ratio scales. 7.3 Traditional Estimates of Reliability Test retest Alternate/equivalent forms Split-half Internal consistency (alphas or KR-20s) Inter-rater (kappa, ICC) According to CTT, \\(r_{xx}\\) is a test property that derives from observed scores  true scores and measurement error. It reflects the extent to which differences in respondents observed scores are consistent with differences in their true scores. 7.3.1 Test Retest Reliability Concerned with the stability of measurement over time. We give a test today, then repeat it at a sensible interval to demonstrate the stability. How do we determine the sensible interval? It depends on the goals of the test. Intelligence testing: stable over weeks, months, years State anxiety: could change in the next hour Practice effects can be problematic for test-retest, therefore 7.3.2 Internal Consistency In multiple item measures of a single construct, items are supposed to all reflect that construct. This means that the individual items should all be correlated with each other. There are several ways to get at this degree of correlation/consistency. 7.3.2.1 Alternate (Equivalent)-Form Reliability Coefficient of equivalence. Give two forms of the test to the same group; potentially measures temporal stability and consistency of response to different item samples (or test forms). 7.3.2.2 Split-Half Method A measure of internal consistency; give test once. Score two equivalent halves of test (e.g., odd items and even items); correct correlation between halves to fit whole test by Spearman-Brown formula. half-length test reliability estimate. 7.3.2.3 Internal consistency Coefficient alpha: Measure of internal consistency for scales with Likert-type scaling (i.e., 1 to 5). Give test once. Score total test. Apply Cronbachs Alpha formula. This is the most common form of reliability. Synonyms are: internal consistency, Cronbachs alpha, alpha. We will learn to calculate these in multivariate, but then examine them critically in psychometrics. They are not without controversy; one of the big problems is that more items (~14 items) almost guarantee a satisfactory alpha (  .80). KR-20s: can provide internal consistency estimates for dichotomously scored items. 7.3.2.4 Interrater Reliabiliy Measure of consistency of ratings of different observers. Used when the human is the measure. 2 raters independently score the responses. Reliability is assessed by: ** correlating the scores assigned by one judge, with those assigned by the other ** computing the proportion of agreement corrected for chance (kappa coefficient) 7.3.2.5 On Reliability Reliability refers to the results obtained with an assessment instrument and not to the instrument itself. An estimate of reliability always refers to a particular type of consistency. Reliability is a necessary but not sufficient condition for validity. Reliability is primarily statistical. 7.4 Defining Validity The ability of a test to measure what it purports to measure. Validity concerns what the test measures and how well it does so. The extent of matching, congruence, or goodness of fit between the operational definition and concept it is supposed to measure An instrument is said to be valid if it taps the concept it claims to measure Validity is the appropriateness of the interpretation of the results of an assessment procedure for a given group of individuals, not to the procedure itself. a matter of degree; it does not exist on an all-or-none basis. always specific to some particular use or interpretation. a unitary concept. involves an overall evaluative judgment. 7.4.1 Traditional Estimates of Validty Face-validity Content validity Construct validity (the all-encompassing validity) Criterion-related validity Concurrent validity Predictive Validity Convergent Validity Discriminant Validity Structural Validity 7.4.1.1 Face Validty: The Un-Validty As its name suggests, face validity is concerned with the appearance of an assessment; How does an assessment look on the face of it? can often be improved by reformulating test items in terms that appear relevant and plausible for the context. Face validity should NEVER be regarded as a substitute for objectively determined validity. Nor can it be assumed that when a (valid and reliable) test has been modified to increase its face validity, that its objective validity and reliability is unaltered. That is, it must be reevaluated. 7.4.1.2 Content Validity Content validty asks, Does the content of the items reflect the domain to be assessed? Procedures for content validation include Subject matter experts Empirical analysis with relevant indicators Item-level and total-scale scores with grades or performance indicators Correlations with other indicators (e.g., math test correlated with reading achievement to rule-out literacy as prerequisite for success). Table of specifications: A two-way chart which indicates the instructionally relevant learning tasks to be measured. Percentages in the table indicate the relative degree of emphasis that each content area Lets pretend that we were going to create a table of specifications for this particular lecture, it might look like this. Objective Knowledge Skills Attitudes % of test; # items Memorize the true-score formula 10%; 1 item 10%; 1 item Define types of reliability 20%; 2 items 20%; 2 items Define types of validity 20%; 2 items 20%; 2 items Retrieve and interpret reliability and validity coefficients from published articles 20%; 2 items 20%; 2 items Write an APA-style instrument entry 20%; 1 item 20%; 1 big item Describe why psychometric evaluation is important 10%; 1 item 10%; 1 item Totals 50%; 5 items 40%; 4 items 20%; 1 item 100%; 9 items 7.4.1.3 Construct Validty Constructs are broad categories, derived from the common features shared by directly observable behavioral variables. They are theoretical entities and not directly observable. Construct validity, then, is the fundamental and all-inclusive validity concept, insofar as it specifies what the test measures. Construct validity was introduced in 1954 in the first edition of APAs testing standards. It is: the extent to which the test may be said to measure a theoretical construct or trait focused on the role of psychological theory in test construction and on the need to formulate hypotheses that can be supported or refuted in the validation process. involves the gradual accumulation of information from a variety of sources that supports its construct validation. 7.4.1.4 Criterion Related Validity Criterion related validity involves correlating the test scores with a relevant present (concurrent) or future (predictive) outcomes. Concurrent validity occurs when the criterion is collected approximately the same time as the scores. Examples might include: Correlation of BDI (Beck Depression Inventory) score with the diagnosis from a licensed psychologist Correlation of performance self-assessment with a supervisor rating Predictive validity occurs when the criterion is collected after a specified time interval. Examples might include: Correlation of a screening test with future diagnosis or occurrence of a screened-for event (e.g., suicide, disease, diagnosis) Correlation of employment screening test score with supervisors performance evaluation 6 months after the hire 7.4.1.5 Convergent and Discriminant Validity We expect moderately high correlations (convergence) of our new test and similarly earlier tests (e.g., correlation of a quantitative reasoning test with a subsequent grade in a math course) If our correlations are too high, then we are creating needless duplication of a test (unless our test is cheaper or shorter). We also need to show that it does NOT correlate significantly with variables from which it should differ (discriminant). low and insignificant correlation of the quantitative reasoning test with scores on a reading comprehension test The multitrait-multimethod demonstrates convergent and discriminant validity.The classic image used to illustrate this matrix can be found here (Trochim, n.d.) 7.4.1.6 Structural Validity Structural validity uses exploratory and confirmatory factor analysis to understand the dimensionality of the measure. For example, IQ is composed of 2 (or more) factors (e.g., verbal and performance) Provides support (or not) for using total or subscale scores. Image of a CFA model illustrating three factors of IQ 7.5 Locating and Interpreting Reliability and Validity in Publications What follows are my personal markups of the measures sections of three manuscripts. Each is well-written and each serves the purpose the research with which it was associated. I review these so that you can begin to Locate and interpret psychometric information from published articles, and Learn how to describe measures/instruments in your own schoalrship. 7.5.1 From Tran and Lee (2014) The first example is from Tran and Lees (2014) stuy. This was a brief report and instruments/measures were not presented in an itemized way. Appraisal and evaluation were 6-items each and were administered pre and post. The reliability measure of internal consistency (alpha coefficient) was .80 at pre-test; and .89 and .85 at post-test. Because they are 6-items each, with each item summed (or mean), I would suggest it is appropriately used as an interval-scale measure. No other reliability or validity information is given. Screenshot of Tran and Lees measures of appraisal and evaluation Single-items measure enjoyability, similarity, accuracy, and how-much-longer. There is no reliability or validity information is provided about them. Because they are single-items, they will likely be treated as interval-level, but are probably more appropriately categorized as ordinal. Screenshot of Tran and Lees single-item measures 7.5.2 From Lui (2020) These were from a full research report (Lui, 2020). Each measure was presented individually with more conventional summary. Experiences with overt racial discrimination were assessed with 9 items. Scaling is 4 points. Given multiple items, it could be utilized on the interval level. Cronbachs alpha (internal consistency, a measure of reliability) was .90 No other reliability or validity info is provided. Screenshot of Luis assessment of overt racism Neuroticism was assessed with 4 items. No indication of scaling; assume it is Likert; interval scaling. Two items were negatively worded so would need to be res-cored. Cronbachs alpha (internal consistency, a measure of reliability) was .62; because this is low they argued that the inter-item correlations (.28) would substantiate their adequacy. Screenshot of Luis assessment of neuroticism Hazardous alcohol use was assessed on a 10-item measure. 4-point scaling; interval scale of measurement. Citations provide some support for validity information. Screenshot of Luis assessment of alcohol use disorders 7.5.3 Exerpt from Nadal (2011) Perceptions of racism with 9 items 2 subscales Prior reports of internal consistency (.90, .83) Prior reports of convergent validity (.24 to .46) Current reports of internal consistency (.878, .673); no justification for the lower alpha. Screenshot of Nadals assessment of racism 7.6 Practice Problem The suggested practice problem for this chapter is to create your own penultimate psychometric template. The goal of this project is to expose you (deeply and interactively) with a variety of write-ups. Please locate 12 write-ups of measures used in research projects. Include at least 4 write-ups (but no more than 6) of ONE measure. The remaining 8 write-ups can be from different measures or same measures. This assignment happens in two stages. First, you will map each of the measures you select (i.e., parallel to diagramming a sentence). Second, looking across the write-ups of those measures, you will create your own template (i.e., a recipe card) for how you will write up a measures in your own papers. Heres an example of how I would map the following write-up of the Mental Health Inventory used in Bikos et al. (2007) First, the screenshot: Heading: name of construct Instrument identification: Name of instrument. Abbreviation. Text-citation. Brief description: Number of items Constructs assessed Intended sample/population More detailed description Scaling and anchors. Sample items. Statement about why instrument format worked well with this research project. Psychometric history Number of psychometric trials with N. Description of factor structure. Mention of support for using a global scale or separate scales. Report of alpha coefficient from previous studies. Psychometric properties in the published ms. Report of alpha coefficient from current study. Assignment Component 1. Screen shots, the APA style citation (7th ed), and an outline of 12 measure write-ups are required. 20 _____ 2. Your psychometric template. Map out an APA-style/JARS-consistent formula/recipe for writing up a measures section in an empirical manuscript. This sh ould be an ideal-scenario kind of writeup for a full-length manuscript or dissertation. 15 _____ 3. Explanation to a grader 5 _____ Totals 40 _____ 7.7 Answer Key The answer to the question, Why is reliability abbreviated \\(r_{xx}\\) and validity abbreviated \\(r_{xy}\\)? r is the symbol for correlation \\(r_{xx}\\) represents the measure (x) correlated with itself (x) \\(r_{xy}\\) represents the measure (x) correlated with another (y). References "],["JEDI.html", "Chapter 8 A JEDI Lecture: Promoting Justice, Equity, Diversity, and Inclusion in Research 8.1 Navigating this Lesson 8.2 Some Context 8.3 Race and Ethnicity Guidelines in Psychology: Promoting Responsiveness and Equity (2019) 8.4 Specific Guidelines for Research in Related Guidelines", " Chapter 8 A JEDI Lecture: Promoting Justice, Equity, Diversity, and Inclusion in Research Screencasted Lecture Link This lesson introduces a collection of guidelines from the American Psychological Association that address research, education, and practice as it relates to individuals with marginalized identities. After introducing these guidelines broadly, my lesson and lecture focus on the elements that specifically address research. 8.1 Navigating this Lesson There is about 1 hour of lecture. 8.1.1 Learning Objectives Learning objectives from this lecture include the following: Describe APAs position on social justice, equity, diversity, and inclusion in research. Recognize ways that psychological research has contributed to marginalization and inequity. Identify ways to design a research project so that it contributes to these larger goals. Access the host of practice guidelines and return to them when they may be useful in professional development. 8.1.2 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Together these articles are an incredible resource for understanding the history of the issue(s) in the profession and getting a sense of theory, research, and prior practices. They are a great reference place if you are seeking to research in these areas. American Psychological Association, APA Task Force on Race and Ethnicity Guidelines in Psychology. (2019). Race and Ethnicity Guidelines in Psychology: Promoting Responsiveness and Equity. Retrieved from https://www.apa.org/about/policy/guidelines-race-ethnicity.pdf I primarily draw from pages 3-7 (Introduction), 10-15.5 (Fundamental Guidelines), 27-33 (Research Guidelines) Multicultural Guidelines: An Ecological Approach to Context, Identity, and Intersectionality, 2017: (501962018-001). (2017). [Data set]. American Psychological Association. https://doi.org/10.1037/e501962018-001 Retrieved from https://www.apa.org/about/policy/multicultural-guidelines.pdf American Psychological Association. (2012). Guidelines for psychological practice with lesbian, gay, and bisexual clients. American Psychologist, 67(1), 1042. https://doi.org/10.1037/a0024659 American Psychological Association. (2015). Guidelines for psychological practice with transgender and gender nonconforming people. American Psychologist, 70(9), 832864. https://doi.org/10.1037/a0039906 8.2 Some Context APA creates (via task forces) and approves (via a process involving a task force, divisional input, and multiple layers of review, finally approved by the Council of Representatives) a variety of professional practice guidelines that are freely and publicly available. There are a couple of distinctions that are important when considering the information provided in the guidelines: First, are they aspirational or mandatory?  Standards (like the Ethical Principles of Psychologists and Code of Conduct) are mandatory  Guidelines are aspirational and informative regarding practice considerations. Second, are they for the practitioner or the client:  Treatment guidelines are client-focused and address intervention-specific recommendations for clinical populations or conditions.  Practice guidelines are practitioner-focus and provide guidance for clinical practice, education, research, and consultation The Guidelines on Multicultural Education, Training, Research, Practice, and Organizational Change for Psychologists were first released in (Association, 2002). In recent years, with explicit acknowledgment that the U.S. is increasingly diverse and that we are at a different period in time, multiple guidelines have been produced and are guided by a foundation of intersectionality. Thus, the 2017 multicultural guidelines (Re-envisioning the Multicultural Guidelines for the 21st Century, 2017):  Are conceptually grounded in a Bronfenbrenner style model with five concentric circles: microsystem, mesosystem, exosystem, macrosystem, and chronosystem,  Recognize three dynamic process that influence the model: power/privilege, tensions, fluidity.  Highlight intersectionality that is shaped by the multiplicity of the individuals social contexts. Below, I list each of the six guidelines and outline the concrete, practical recommendations associated within the applications to research subsection (Re-envisioning the Multicultural Guidelines for the 21st Century, 2017). These are my paraphrases  and, because I provided the citation in this paragraph, I do not provide secondary citations. Also, in many of these subsections the Task Force makes recommendations for research topics. I do not list those. Guideline 1. Psychologists seek to recognize and understand that identity and self-definition are fluid and complex and that the interaction between the two is dynamic. To this end, psychologists appreciate that intersectionality is shaped by the multiplicity of the individuals social contexts. Research often looks downstream for cause (i.e., individual behavior that may be associated with a social category membership) when we can also look upstream for macro societal processes that define systems of social inequality (laws, cultural mores, institutional practices, public policies). Quantitative and qualitative can be used effectively to answer some of these questions. That said, qualitative and/or mixed methods may be more sensitive to social complexities because of the use of open-ended versus checkboxes; grounded/emergent rather than a priori theory. If engaged in scholar-activism or participatory action research, be mindful that the project isnt just serving those on the scholar side of the equation. Consider self-identification of demographic data. Recognize multiple identities. Guideline 2. Psychologists aspire to recognize and understand that as cultural beings, they hold attitudes and beliefs that can influence their perceptions of and interactions with others as well as their clinical and empirical conceptualizations. As such, psychologists strive to move beyond conceptualizations rooted in categorical assumptions, biases, and/or formulations based on limited knowledge about individuals and communities. Be cognizant and responsive to how design, methodology, and data analysis are shaped by personal worldviews and assumptions. Culturally informed empirical studies strive for collaboration (valuing the perspectives and sociocultural locations and identities of research participants) and self-reflexivity on the part of the researcher. Guideline 3. Psychologists strive to recognize and understand the role of language and communication through engagement that is sensitive to the lived experience of the individual, couple, family, group, community, and/or organizations with whom they interact. Psychologists also seek to understand how they bring their own language and communication to these interactions. Culturally adapt measures, research questions, practices (not stated in the article, but [Byrne, 2016] outlines an entire process of culturally adapting measures). Informed consent should be provided in the participants primary language. Incorporate members of the community in all aspects of the research planning and implementation. Guideline 4. Psychologists endeavor to be aware of the role of the social and physical environment in the lives of clients, students, research participants, and/or consultees. A 1946 call for community action research and practice remains the articles recommendation. Not mentioned in the article, multi-level (statistics) approaches that can accommodate individual- and contextual- level inputs in the same analysis can be useful. Guideline 5. Psychologists aspire to recognize and understand historical and contemporary experiences with power, privilege, and oppression. As such, they seek to address institutional barriers and related inequities, disproportionalities, and disparities of law enforcement, administration of criminal justice, educational, mental health, and other systems as they seek to promote justice, human rights, and access to quality and equitable mental and behavioral health services. Leverage methodological diversity. For example, pair quantitative methods with qualitative, discovery-oriented, and/or community-based participatory approaches. Establish relationships with community partners to collect and analyze data with and from those communities. As more research is published, employ meta-analysis to draw broader conclusions. Comparative research between dominant and non-dominant help-seeking individuals may be used to better understand differences in health care and, in particular, identify unique demographic patterns that correlate with mental health disparities. Guideline 6. Psychologists seek to promote culturally adaptive interventions and advocacy within and across systems, including prevention, early intervention, and recovery. Foster the development of culture-centered interventions. Seek to include research participants who are diverse across multicultural variables. Develop/adapt research measures for multicultural contexts. Document the evaluation/adaptation of evidence based treatments (EBTs) to culturally and linguistically diverse contexts. Guideline 7. Psychologists endeavor to examine the professions assumptions and practices within an international context, whether domestically or internationally based, and consider how this globalization has an impact on the psychologists self-definition, purpose, role, and function. Contribute to a global helping paradigm that links psychology, psychotherapy, and indigenous healing across national boundaries. International communities may have no (or different) regulatory standards. In this case, consult with local NGOs, health clinics, and stakeholders to abide by both by U.S. (IRB) and local standards. Guideline 8. Psychologists seek awareness and understanding of how developmental stages and life transitions intersect with the larger biosociocultural context, how identity evolves as a function of such intersections, and how these different socialization and maturation experiences influence worldview and identity. Pay close attention and inform themselves of the intersectional considerations that participants present. How do these influence interpretations of findings regarding self, identity, group membership, and the consistency of presentation across groups of a psychological phenomena or concept? A qualitative component may help unravel this. Guideline 9. Psychologists strive to conduct culturally appropriate and informed research, teaching, supervision, consultation, assessment, interpretation, diagnosis, dissemination, and evaluation of efficacy as they address the first four levels of the Layered Ecological Model of the Multicultural Guidelines. Recognize the limited generalizability of random clinical trials (RCTs); this may reduce the effectiveness of evidence based treatments (EBTs) with diverse groups. Review culturally adapted interventions or evidence of fidelity to the original approach. Guideline 10. Psychologists actively strive to take a strength-based approach when working with individuals, families, groups, communities, and organizations that seeks to build resilience and decrease trauma within the sociocultural context. Determine and employ local definitions of resilience and other strengths-based outcomes. Recognize how these definitions change as a function of intersecting identities (e.g., sex, gender roles). And again: quant + qual. ..before leaving this article, check out the 65+ pages of reference and the extensive appendices (definitions, case studies). 8.3 Race and Ethnicity Guidelines in Psychology: Promoting Responsiveness and Equity (2019) The lecture continues with a focus on the 2019 race and ethnicity guidelines (Race and Ethnicity Guidelines in Psychology, 2019). Because these are the central focus of the lecture and my hope is that you will check access them directly, I have intentionally not written additional notes. 8.4 Specific Guidelines for Research in Related Guidelines The following research-related guideline is from the Guidelines for Psychological Practice with Lesbian, Gay and Bisexual Clients (American Psychological Association, 2012). Guideline 21. In the use and dissemination of research on sexual orientation and related issues, psychologists strive to represent results fully and accurately and to be mindful of the potential misuse or misrepresentation of research findings. Be aware of the potential influence of overt and covert bias Exercise care that reports are thorough and that limitations are fully disclosed and discussed Remember that there are subgroups within LGBTQ+ communities that are not included in research samples; take their absence into consideration when applying/discussing findings Be extra careful when citing/quoting research findings from third parties Avoid false or deceptive statements; accurately publish research results Remember that media outlets lack psychological training; emphasize to journalists the complexity and limitations of research findings Another research-specific guideline is from the Guidelines for Psychological Practice with Transgender and Gender Nonconforming People (American Psychological Association, 2015). Guideline 15. Psychologists respect the welfare and rights of TGNC participants in research and strive to represent results accurately and avoid misuse or misrepresentation of findings. Provide a range of options for capturing demographic information about TGNC people so that TGNC people may be included and accurately represented. One group recommends First asking sex assigned at birth Following with a question about gender identity Because the TGNC population may be hard to reach (geographically dispersed, diverse, stigmatized, hidden), consider collaborative research methods such as participatory action research in which the members are integrally involved. Be cautious with media. Journalists may have limited knowledge about the scientific method and there is potential for misinterpretation, exploitation, sensationalization. References "],["OpenScience.html", "Chapter 9 Orientation to Open Science 9.1 Navigating this Lesson 9.2 The Crises 9.3 Open Science: What &amp; Why 9.4 Open Science: Where 9.5 Open Science: Who are the Stakeholders? 9.6 Open Science: How 9.7 And also, Preregistration 9.8 Im a Graduate Student  What does it mean to me?", " Chapter 9 Orientation to Open Science Screencasted Lecture Link This lesson focuses on  9.1 Navigating this Lesson There is just less than 1 hour of lecture. 9.1.1 Learning Objectives Learning objectives from this lecture include the following: Distinguish replicability from reproducibility. Define the replication/reproducibility crisis. Describe how pre-registration can help with the replication/reproducibility crisis. Identify advantages and disadvantages of data sharing To the discipline To the researcher To the research participant Obtain an ORCID 9.1.2 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. Jhangiani, R. S., Chiang, I.-C. A., Cuttler, C., &amp; Leighton, D. C. (2019). Research Methods in Psychology. https://doi.org/10.17605/OSF.IO/HF7DQ Chapter XIII: From the replicability crisis to open science practices (60) Quick, efficient summary of the what created the replicability/reproducibility crisis and what psychology is (and isnt) doing to address it. Alter, G., &amp; Gonzalez, R. (2018). Responsible practices for data sharing. American Psychologist, 73(2), 146156. https://doi.org/10.1037/amp0000258 One of a 4-part special section of the America Psychologist devoted to addressing issues related to data sharing. All four articles are great  this was one of the two that are very practical. The others are cited in this lecture and archived in the SP readings folder. 9.2 The Crises 9.2.1 The Replicability Crisis Replicability is re-performing the experiment with new data. Summarizing results of replicability studies, Stevens (2017) noted the following: In medicine, only 25% of previously published studies were able to replicate/confirm statistically significant effects. In behavioral economics, 61% In psychology, 36% (when 97% of the original studies did so) What accounts for these discrepancies? Differences in design and methods between the original and replication studies; False negatives (Type II error) in the replication; False positives (Type I error) in the original study; Confirmation bias at any step in the original study, such as Developing tests that attempt to confirm rather than disconfirm hypothesis Perceiving behaviors in a manner that align with expectations (as opposed to outcomes), Reporting the confirmatory (and ignoring the disconfirmatory) results (p-hacking) The file-drawer problem: inability to publish results (original or replication) with non-significant results. 24% of all NIH-funded trials aimed at evaluating the efficacy of psychological treatments for major depression were not published; when included in meta-analyses, this led to a 25% reduction in the estimated effect of psychotherapy (Hengartner, 2018). For CBT-specific trials, when unpublished trials were included in a meta-analysis, there was a 37% reduction in the estimated efficacy of the intervention. 9.2.2 The Reproducibility Crisis An article [] in a scientific publication is not the scholarship itself, it is merely advertising of the scholarship. The actual scholarship is the complete software development environment and the complete set of instructions which generated the figures (Buckheit &amp; Donoho, 1995). Reproducibility is reperforming the same analysis with the same code, using a different analyst. In most published research, this is not possible. In a survey of 441 biomedical articles (2000 to 2014), only one was fully reproducible. 9.3 Open Science: What &amp; Why Core principles of science (at a time when the integrity of science is being questioned) include (Alter &amp; Gonzalez, 2018): Research transparency: the methods are described with sufficient detail such that the study can be replicated; also codebooks, analytic/processing scripts (including those used to create tables and figures) are available Reproducibility: verify the published findings with the same dataset. Replicability: find similar share with a different/new data set. Data sharing: some version of the data (raw/primary, de-identified, perhaps blurred) available freely or through an application/vetting process 9.3.1 Research Transparency Alter and Gonzalez (2018) suggested that research transparency includes more than sharing of data. Research transparency also includes the procedures used to create and analyze the data. Why? Data are often refined, corrected, and manipulated before analysis. These steps may be part of the process that makes a statistically significant finding possible; that is, other approaches to scrubbing/scoring data will produce different (unstable) results. Transparency requires that these steps be clearly articulated  in order and with all details of the process. 9.3.2 Who owns the data? It depends  and is worth careful consideration. Institutions:  While the PI is often considered to be the custodian/steward of the data, it is often contractually understood that the institution owns data when it is externally funded (e.g., NIH, NSF). The principal investigator (PI)/lab? Maybe. Even in the absence of ownership the P.I. is likely the responsible party. The community? At least as co-owner? From community participatory action or critical-ideological approaches, the community should likely have a say in data management. 9.4 Open Science: Where 9.4.1 Data Repositories: Institutions that make commitments to preserve, maintain, and distribute data over time. They also make data citable by assigning persistent identifiers (e.g., the DOI in journal articles). Domain specific: provide services for a specific field. Focus on limited types of data and invest heavily in curating it for reuse.  Examples: ICPSR (quantitative data for social and behavioral research), Databrary (videos used by developmental psychologists). General: serve a broad range of disciplines and provide fewer data curation services. Designed to be self-service in that the depositor provides documentation and meta-data (e.g., data about data such as details in a codebook). Mendeley, Figshare, Dataverse Institutional: operated by libraries with a broad mission to document and preserve all the research produced by faculty, staff, students. The scope and services varies by institutions. Large universities hire staff with data management, documentation, and preservation services. 9.4.2 Journals: Supplemental files Many journals provide the option of uploading supplemental files. These could be a variety of things: testing/interview protocols, supplemental tables/figures, and data/meta-data. 9.5 Open Science: Who are the Stakeholders? 9.5.1 Groups Research data have the potential to harm individuals and their communities (Ross et al., 2018). We generally apply the ethical principle of beneficence to the individual; but we are wise to think of it as it applies to communities as well. Consider the case where a research team collected blood samples from members of the Havasupai tribe for a diabetes study. Later it was discovered that samples had been shared with other researchers to study issues including inbreeding, human migration, and schizophrenia. Separate from whether individual participants were identified, this resulted in social and psychological harm to the tribe as a whole. 9.5.2 Individual Research participants A substantial objection to sharing research data is that confidential information about research participants will be protected. Evaluating harm from disclosure risks can be considered bidimensionally: Probability of reidentification Potential harm Lo Hi Lo Hi Consider the following examples in each of the quadrants. Low potential for harm: Opinions in a national poll, perception tasks in an experimental setting High potential for harm: Mental health, drug use, criminal activity, sexual behavior Hi probability of re-identification: Direct identifiers (name, phone number, SSN) Geospatial locations Longitudinal designs with repeated interviews and contextual info (grade, school) Some data cannot be completely anonymized without destroying its research value. 9.5.3 The Common Rule The Common Rule (Federal Policy for the Protection of Human Subjects (Federal Policy for the Protection of Human Subjects (Common Rule, 2009) is the chartering document guiding IRB activity. The chartering document for institutional review boards (IRB) defines minimal risk as it relates to research endeavors. To the degree that the probability and magnitude of harm or discomfort in the research activity does not exceed those ordinarily encountered in daily life or during a routine physical or psychological evaluation, data can be shared without any additional precautions. Historically, informed consent language said something like, Your data will only be available to members of our research teamat the end it will be destroyed. The new version of the Common Rule (Protections (OHRP), 2017) includes guidelines for broad consent which covers storage and future secondary research with data that includes identifiable protection. The Common Rule suggests that participants should be given a general description of the types of research that may be conducted with the information collected from them and informed about the types of identifiable private information that will be kept and the types of researchers who may have access to that information. This is all emerging  dynamic consent has been suggested as a way to allow patients to decide who can use their health data for research. Patients who have provided samples (e.g., blood, DNA) get texts/surveys through their phones to grant/deny consent for new uses. 9.5.3.1 Data creators Among a variety of scientists, an NSF funded study reported that psychologists were the most negative about data sharing (Martone et al., 2018), with 30% indicating that data should be shared. What are the concerns (Martone et al., 2018)? Fear for reputation: making errors and being called out. Fear of being scooped: someone else will beat me to my next question. Fear of liability: release of primary data for certain participants might lead to prosecution. Its a lot of work. I have to do this, too!?!? My data are far too complex/sophisticated to be understood by anyone else on the planet. My data are not useful beyond the purposes I have planned for them. How will the field develop/evolve if we just reanalyze old data? Yet, there are counterpoints (Martone et al., 2018): The issue of who is harmed by sharing data needs to be balanced against who is harmed by not sharing data? (p. 117) The Issue A Counterpoint Reputation/Liability What if errors (if any) are undiscovered? Or findings are spurious (and only because of biased ways of data preparation)? Being Scooped Curiously, in microbiology, the original data creators tended to publish two years after the data were made publically available; other authors tended to publish five to six years after the data were made available. Unrewarded effort If data are essential products of scholarship, those who create data must be appropriately acknowledged and rewarded ((Alter &amp; Gonzalez, 2018), p. 153). Data isnt useful beyond the single project Martone (Martone et al., 2018) recounted the results of the VISION-SCI project where the scientific community made individual data sets available (even those with NS effect  file-drawer and background data). Although individual studies (usually with restricted samples) produced unstable and inconsistent findings, the combined data provided a fuller sampling of the syndromic space (p. 114) and resulted in robust predictive models. The field will stagnate with no new data being collected Even the most amazing, longitudinal sets such as the High School and Beyond longitudinal set that has been used in so many examples (High School &amp; Beyond (HS&amp;B) - Overview, n.d.)(High School &amp; Beyond, National Educational Longitudinal Set) become obsolete and are replaced by newer samples and improved measures/techniques. Other practical considerations: Authors may request (and journals may grant) an embargo period ranging from a few months to two years (or at least until the article is published) before the data is released (Martone et al., 2018). When published data are part of larger data sets, only the variables used in the study are the only ones required to be made available. Citations are the basis of scholarly recognition. PIs are wise to use a depository that will provide a formal citation (5 elements: author, title, date, publisher/distributor, location; with persistent identifier) such that the data will be included in the reference list. When we make data (and/or script/code) available in a repository  we should list it on our resume/CV! Similarly, scripts/code for all aspects of data management, analysis, and manipulation can be formally prepared, archived, and cited. 9.6 Open Science: How 9.6.1 Regarding research transparency Establish (now, while you are just learning) the regular practice of a standard research workflow. It should Be ordered, such that it maps along with the results section of the published manuscript. Contain all of the script/code/syntax (in our case, the .rmd file) that does everything: defines variables, cleans data, includes/excludes data, manages missingness, scores scales/subscales, tests assumptions, runs the analyses, creates figures/tables. Include narration of what you are doing and your rationale for doing so. And also a bug log; a document that notes errors and corrections. This should not be a disorganized set of statistical commands (Alter &amp; Gonzalez, 2018, p. 148) Alter and Gonzalez (2018) went further to suggest that the script/code should be keyed to the final publication (e.g., page or paragraph number). 9.6.2 Regarding data ownership Get clarification on responsibilities and restrictions regarding the data that was used (note I did not write your data) in your projects (institutional, legal [FERPA, HIPAA, The Common Rule]). When starting a new project, include as much detail as possible in the IRB application and informed consent about all the possible uses for data. Below is an excerpt from a recent IRB application that projects how data might be used (credit to Tom Carpenter, PhD, for examples of language to use in the informed consent). Confidentiality The data we are using is completely de-identified and is already available to instructors as well as their chairs, deans, and members of tenure/promotion committees. All data that is retained for the purpose of the study may also be used in future research, presentations, and/or for teaching purposes by the Principal Investigator listed above. Consistent with both journal/guild expectations and the ethical principles of open science, a fully anonymous and non-identifiable version of the dataset may be posted online (e.g., to the APA-endorsed Open Science Framework [www.osf.io] or to the journal, submitted with the research article). No data posted will contain any information that could identify participants in any way, either directly or indirectly. All data will be thoroughly inspected by the research prior to posting to confirm that no participant-provided responses could inadvertently identify or expose a participant. Posting data (commonly referred to as data sharing) is necessary for reproducibility and replicability in science, allows peer reviewers and meta-analysts to check statistical assumptions, protects the field against data fraud, and is increasingly seen as an ethical obligation within psychological science. Bikos RVT IRB application, November 2020 9.6.3 Regarding Data Sharing Alter and Gonzalez (2018) recommendeded using domain-specific repositories whenever possible. Because they are more connected to the research community(ies) that will use them, they will be most likely to provide the discipline-specific curation services that will maintain the value for future reuse. Alter and Gonzalez (2018) discouragde attaching research data as part of the supplementary materials associated with the publication because publishers do not manage research data with the same best practices that a data repository would. For example they may convert research data to text or pdf files and the materials may not be as discoverable as they would in a repository. Best practices in data sharing are FAIR: Findable, Accessible, Interoperable, Resuable (Martone et al., 2018). Check out Table 2 in the Martone et al article for the details and implications of these practices. 9.6.4 More Resources: Alter and Gonzalez (2018) provided a list of resources about data sharing and open science. The resources that are websites are likely updating as the field evolves. The Open Science Framework (OSF) is one that is frequently referenced in psychology. The help pages have a section devoted to FAQs and best practices  especially about the practical steps/logistics such as version control, file naming, and making a data dictionary: https://help.osf.io/hc/en-us 9.7 And also, Preregistration In pre-registration, researchers describe their hypotheses, methods, and analyses before a piece of research is conducted  in a way that can be externally verified (Veer &amp; Giner-Sorolla, 2016). This is emerging, but there are two general types: Reviewed pre-registration or registered report: A cooperative model between reviewers and researchers that involves feedback to the research design that can be incorporated before the study is conducted. This can be accompanied by a guarantee of publication regardless of the outcome. Unreviewed pre-registration: No review prior data collection. The research plan is written and time-stamped before the study. The authors can conduct research as usual. In both, authors can still follow-up analyses with exploratory research. Advocates of pre-registration suggest (Veer &amp; Giner-Sorolla, 2016): It prioritizes theory and method over results It distinguishes confirmatory from exploratory research It reduces publication bias It reduces reporting bias within a single study It offers researchers additional input and review before they start It can lead to faster dissemination (particularly with registered reports) Concerns about pre-registration: More work? For researchers and reviewers. Will it dampen exploration?  van t Veer and Giner-Sorolla (2016) have suggested that exploratory work should still be reported. Whats the value of a null literature (i.e., a bunch of studies with non-significance)?  It can save the scientific community time and effort.  It could help identify methodological problems such as being underpowered. Idea theft  will others steal designs?  Pre-registered studies can stay private (in OSF up to 4 years) until the project is finished. van t Veer and Giner-Sorolla (2016) provided guidance in the form of templates/instructions for registering a study for social psychology. Lets go take a look at the OSF to see their pre-registration model. Start with the decision tree Get your form; theres even an .rmd version! Lets peek at the Google doc 9.8 Im a Graduate Student  What does it mean to me? Most journals now require a persistent identifier (ORCID) for researchers. These are connected to all published articles. You can obtain yours at: https://orcid.org/register You can talk with your RVT about trying out pre-registration with lab projects. APS (Association of Psychological Science) are a signatory to the Transparency and Open Science Guidelines (TOPS). Lets take a quick look at what that means for publishing: https://www.psychologicalscience.org/publications/open-science In participating journals, articles can be awarded badges for: https://www.psychologicalscience.org/publications/badges Pre-registered Open Data Open Materials As you plan your research projects, think ahead to the journals to which you might submit. See if they are part of such a process. Although it may delay your start time, if they are part of the registered reports process, you might be guaranteed submission if your pre-registration is reviewed and approved by the journal. sessionInfo() R version 4.0.4 (2021-02-15) Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 10 x64 (build 18362) Matrix products: default locale: [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United States.1252 [3] LC_MONETARY=English_United States.1252 [4] LC_NUMERIC=C [5] LC_TIME=English_United States.1252 attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] psych_2.1.3 loaded via a namespace (and not attached): [1] rstudioapi_0.13 knitr_1.33 magrittr_2.0.1 mnormt_2.0.2 [5] lattice_0.20-41 R6_2.5.0 rlang_0.4.11 stringr_1.4.0 [9] tools_4.0.4 parallel_4.0.4 grid_4.0.4 tmvnsim_1.0-2 [13] nlme_3.1-151 xfun_0.22 jquerylib_0.1.4 htmltools_0.5.1.1 [17] yaml_2.2.1 digest_0.6.27 bookdown_0.22 sass_0.3.1 [21] evaluate_0.14 rmarkdown_2.7 stringi_1.5.3 compiler_4.0.4 [25] bslib_0.2.4 jsonlite_1.7.2 References "],["writing-empirical-manuscripts.html", "WRITING EMPIRICAL MANUSCRIPTS", " WRITING EMPIRICAL MANUSCRIPTS "],["APAstyle.html", "Chapter 10 The APA Style Manuscript 10.1 Navigating this Lesson 10.2 APA Style as Epistemology (or Worse) 10.3 As We Dive into the Specifics 10.4 The JARS: The Core of APA Style", " Chapter 10 The APA Style Manuscript Screencasted Lecture Link This lesson focuses on APA style. While a significant portion of the material focuses on the mechanics of APA style, I also consider: APA style as epistemology  and its relationship with power, privilege, and racism. JARS: Journal Article Reporting Standards Section by section Consideration of writing as a developmental process that occurs throughout grad school and into the profession Stylistic issues Hallmarks of APA style Reducing bias 10.1 Navigating this Lesson There is about 1 hour and 45 minutes of lecture. The R markdown file used to create this lecture as well as all of the figures are available at the OERs GitHub site. 10.1.1 Learning Objectives Learning objectives from this lecture include the following: Identify the cultural characteristics of APA style. Identify two ways that Thompson (2004) has suggested that APA style perpetuates Whiteness and patriarchy in the academy. List the components of an abstract. Describe why JARS matters. Begin memorizing the minutia of APA Style for writing empirical manuscripts/journal articles (no particular order). 10.1.2 Readings &amp; Resources In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list. American Psychological Association. (2020). Publication manual of the American Psychological Association: The official guide to APA style. (Seventh edition.). American Psychological Association. Im guessing youll use this more days than not, for the rest of your education. Tran, A. G. T. T., &amp; Lee, R. M. (2014). You speak English well! Asian Americans reactions to an exceptionalizing stereotype. Journal of Counseling Psychology, 61(3), 484490. https://doi.org/10.1037/cou0000034 I use this article in several analyses in the ANOVA series as well as in this lesson when I compare/contrast it to the requirements of APA Style. This article was pubbed in 2014; but I will compare it to the 7th edition (2019) standards. Cooper, H. (2020). Reporting quantitative research in psychology: How to meet APA style journal article reporting standards (Second edition, revised.). American Psychological Association. https://alliance-primo.hosted.exlibrisgroup.com/permalink/f/rpqmv/CP71332049420001451 The e-text version of this may be available at your library. This resource offers section-by-section instruction of the reporting standards and provides numerous examples of writing APA empirical manuscripts. Madigan, R., Johnson, S., &amp; Linton, P. (1995). The language of psychology: APA style as epistemology. American Psychologist, 50(6), 428436. https://doi.org/10.1037/0003-066X.50.6.428 Madigan et al. (1995) argued that as we learn APA style we are inculcating the professional values of our discipline (and we do this without awareness). Thompson, A. (2004). Gentlemanly Orthodoxy: Critical Race Feminism, Whiteness Theory, and the APA Manual. Educational Theory, 54(1), 2757. https://doi.org/10.1111/j.0013-2004.2004.00002.x Critiquing the 5th edition of the style manual (were now on the 7th) Thompson (2004) pointed out how aspects of APA style contribute to preserving Whiteness. Appelbaum, M., Cooper, H., Kline, R. B., Mayo-Wilson, E., Nezu, A. M., &amp; Rao, S. M. (2018). Journal article reporting standards for quantitative research in psychology: The APA Publications and Communications Board task force report. American Psychologist, 73(1), 325. https://doi.org/10.1037/amp0000191 Yet another copy of the most current JARS. You can also find them in the style manual and on their own website: https://apastyle.apa.org/jars/glossary White Supremacy Culture. (n.d.). DRworksBook. Retrieved August 8, 2020, from https://www.dismantlingracism.org/white-supremacy-culture.html Identifies characteristics of White Supremacy Culture in organizations (often used to describe academia). 10.2 APA Style as Epistemology (or Worse) A 1995 article (Madigan et al., 1995) in the American Psychologist compared APA style to that of other disciplines (history, literary criticism) and argued that APA Style is its own writing genre characterized by (among other things): A story schema: introduction, method, results, discussion  Seems so linear; but this is rarely the case (research is messy) A depersonalized language of disagreement that focuses on the empirical process and away from investigators as individuals (e.g., The primary criticism is that the threshold-setting procedures used in previous experiments are not adequate to ensure that). The goal is a collaborative, cumulative endeavor based on research data. Hedged conclusions: balancing a need to have substantive conclusions that do not extend beyond the data. We use the words, tend, suggest, and may. See Table1. A system of headings/subheadings (rather than narrative transitions) Paraphrasing rather than directly quoting other works.  Giving authors more flexibility in representing others perspectives. Multiple authors (perhaps contributing to more subdued prose). Heavy use of citations introduction and discussion so that the research is placed within an ongoing stream of empirical studies. Language that does not call attention to itself. It can be described as: self-effacing and low-profile. The style manual has grown from its 7-page writers guide in the Psychological Bulletin (1929) to 427 in the 7th edition (2019), today. Madigan et al. (1995) suggests that the process of mastering APA style, one is enculturated into psychology. That is, we learn APA style  we inculcate empiricist values (i.e., unarticulated practices that reflect fundamental attitudes and values of psychologists (p. 428). As such, APA style is epistemological. Nearly a decade later, Thompson (2004) examined APA style through the lens of critical race feminism and Whiteness Theory. Thompson argued that the expectations regarding clarity precision, appropriateness, sensitivity, and objectivity likely contribute to the academys investments in Whiteness and patriarchy. While her focus was on APA Style, she suspected that her critique would generalize to other style guides (e.g., Chicago, MLA). Thompsons (2004) article focused around the gender/sexuality and race values codified by the APA manual (at the time of her article it was the 5th edition). She conducted an analysis of its power and property investments and organized her arguments in five themes: Property Rights: PWIs have treated refereed scholarship (but not indigenous or community knowledge) as intellectual property, demarcated with a certain class. That is, individuals own knowledge. Evidence includes: Using last names as a shorthand reference for work (e.g., Dik &amp; Duffys 2012 CVQ). Tendency to cite own work rather than say, When I previously said The style manual indicates that principal authorship and order of authorship credit should reflect the relative contributions of persons involved (7th ed, APA 1.22) and that relative status should not determine authorship order. Thompson argued that power dynamics (especially around race and gender) likely interfere with this principle. The 7th edition has reduced citations of articles with three and more articles to First author et al., YEAR for all citations. Regarding, ownership of knowledge  does it belong to the researcher or the community from which it came? Community knowledge can be studied but not cited. And what about institutions. What if knowledge came from the Black Church? How does one cite that? Precedent and pedigree: In the social sciences, we are expected to cite and give credit to relevant earlier works. Knowledge is seen as cumulative. Citations are essential. No unhedged statement (p. 45) is made without a citation; and in introductory sections, citations are often included with claims that seem obvious! This establishes the requisite lineage. Self-citations, expected citations (of the gurus), citations of colleagues exist IN TENSION with a citation economy (page limits, afterall). The requirement that scholars locate their project in the context of the existing peer-reviewed literature serves to keep out ideas/projects that would be challenging to the existing power structure. Proceduralism: APA authors learn to address an audience unmarked (as if they were white, male, heterosexual) by gender or race as a sign of professionalism (p. 48). Standardized Format: a four section structure: Introduction, Method, Results Discussion; it could be that the experiences of marginalized and oppressed groups cannot be captured by this scientific narrative structure. Standardized Style: prizing scientific appearance and elegance. Thompson (2004) follows the guidelines regarding the use of the slash (/) and how it is impossible to standardize to the degree that it works for all groups. The First author et al., (year) citation contributes to both gender- and color-blindness. ON the one hand is it fair. On the other hand, it obscures the person of the author. APAs prohibition against footnotes minimizes the good stuff (the most juicy arguments are always in the footnotes). Protocol: Propriety or protocol represents conduct that signifies ones understanding of prevailing relations of power, authority and legitimacy. The style manual (7th ed, Chapter 5, e.g., 5.2) acknowledges the importance of sensitivity and the avoidance of pejoratives to reference groups of people. Thompson indicates that this is admirable it fails to address unequal power relations. Further, distinctions between what is insensitive and pejorative may be invisible to those in positions of privilege. The gentlemans agreement: APA style is characterized language that conveys professionalism and formality (7th ed, 4.7, 4.8) and differences should be presented in a professional and noncombative manner (7th ed, 4.7). Thompson (2004) is concerned that while this is offered with the hope of pluralism and the creation of safe spaces, it causes controversies to be ignored or dismissed and may bolster complicity in racism. 10.3 As We Dive into the Specifics Please keep the perspectives of these authors in mind. Lets also look at the characteristics of White Supremacy Culture in organizations (White Supremacy Culture, n.d.). As we tour through the components of APA style, what resonates with this list? Refer to the .pdf handout or website for more definitions, descriptions, examples, and antidotes. Perfectionism Perfectionistic culture Worship of the written word Only one right way Either/or thinking Concentration of power Power hoarding Paternalism Defensiveness Right to comfort Fear of open conflict Individualism Im the only one Progress is more/bigger Objectivity Quantity over quality Sense of urgency 10.4 The JARS: The Core of APA Style The JARS [Journal Article Reporting Standards; Appelbaum et al. (2018)] were first introduced in a 2008 feature in the American Psychologist (Reporting Standards for Research in Psychology, 2008) and were included in the 6th edition of the style manual. The updated JARS, published in 2018, expanded the types of quantitative research (JARS-Quant) and included standards for reporting qualitative (JARS-Qual) and mixed methods (JARS-Mixed). Chapter 3 of the 7th edition is devoted to JARS. It contains numerous tables, definitions/explanations, and a flowchart. The JARS are an attempt to represent what is common across approaches. There is a recognition that specialties/sub-specialties use different terminology. The terms, therefore, should be treated as placeholders and be updated to reflect the various research traditions. In each of the sections below, I list both the APA style recommendations and JARS elements  which are somewhat annoyingly separate, adjacent, and overlapping. In the next section I used text-citations to also refer to the section numbers of the 7th edition of the APA style manual. Additionally, because this OER is publicly available (i.e., not just used in my classroom), I have not copied the JARS elements into this document. They are freely available here 10.4.1 Title, Authorship, Author Note (APA 2.3) QUIZLET: A manuscript title should Use abbreviations whenever possible Contain at least 30 words Be fully explanatory when standing alone Begin with the words, A Study of The title page of a manuscript includes the Authors name Authors institutional affiliation Running head Short title All of the above 10.4.1.1 Title (APA 2.4) Concise statement of main topic of the research, Identify the variables or theoretical issues under investigation (and the relationship between t Addhem), Focused and succinct (no prescribed word or character limit per the style manual; but a journal might have one). Avoid empty words/phrases like A study of, An investigation of The lecture further reviews JARS elements. 10.4.1.2 Authorship/Byline (APA 2.5) &amp; Affiliation (APA 2.6) Primary contributors; Institutional affiliation AT THE TIME of the study, no more than 2 institutional affiliations (and they both need to have contributed equally) Very specific style guidelines (with superscript notations) for connecting authors and their affiliations In the order of contribution  lots of ethical, practical, and sensitive considerations about who gets to be an author and in what order. Sticky Issues about Authorship Faculty as first authors Ongoing projects with years of investment sponsored by faculty Who gets the call? Order between equal contributors (e.g., Singer &amp; Willett) In equal contributions its ok (not ideal) to mention in the author note GOAL: name on a project, less concerned about author order Generally, graduate projects include the faculty sponsor as an author (last at SPFC conference; likely elsewhere at professional conferences or publication) Author-order rubrics can be useful to guide the decision 10.4.1.3 Author Note (APA 2.7) Place the author note at the bottom half of title page. There are more specific instructions in style manual. Generally author note has four paragraphs: ORCID iDs https://orcid.org Changes in affiliation subsequent to the time of the study, [Authors name] is now at [new affiliation]. Can also be used if an author is deceased. Disclosures and acknowledgements (i.e., study registration, open practices and data sharing, related reports, conflicts of interest, financial or other assistance). Contact information for corresponding author. Requires full name, complete mailing address, and e-mail. Prescribed format: Correspondence concerning this article should be addressed to [authors name], [complete mailing address]. Email: author@institution.edu The lecture further reviews JARS elements. 10.4.1.4 Running Head (APA 2.8) Abbreviated title printed at the top of the pages of a ms or pubbed article to identify it for the readers Max of 50 characters (counting letters, punctuation, spaces between words). If the title is already 50 characters or fewer, the full title can be sued. Avoid abbreviations in the running head, although the ampersand can be swapped (&amp; for and). Appears flush left in all uppercase letters at the top of the title and subsequent pages 10.4.1.5 Manuscript Page Headers/Page Numbers (APA 8.03) Number consecutively, beginning with the title Identify each page with the running head along with the page number To facilitate a blinded review, do not include your name in these Use the automatic functions of the word-processer to generate page headers and page numbers 10.4.2 Abstract (APA 2.8, 3.3) QUIZLET: An abstract should Appear on the same page above the title and introduction Be single-spaced and set with larger margins Begin on page 2 Be no longer than 3% of the text Abstract lengths vary from journal to journal; the typical range is from ___ to___ words. For reala good abstract is: Concise and specific Nonevaluative Coherent and readable Loaded with keywords May be a single paragraph (no indentation of first line) or structured (still no indentation, but labels inserted for the prescribed sections). 10.4.2.1 Recipe for an Abstract Identify the problem under investigation (1 sentence) Identify the participants and salient characteristics Identify the experimental method, including the apparatus, data gathering procedures, complete test names, etc. Identify findings (including statistical significance levels) Identify conclusions and implications/applications. Avoid boilerplate sentences.  At the end of an abstract, I often read, Findings and implications will be discussed. This is boilerplate because everyone says it. Its also empty and a waste of words because it tells us NOTHING about the study. The style manual includes outlines for a variety of types of manuscripts. The lecture further reviews JARS elements. 10.4.2.2 Keywords Keywords include single words, phrases, or acronyms that describe the most important aspects of the paper. The purpose is indexing in databases (its what we search on in database like PsychInfo). 10.4.3 Introduction (APA 2.11) QUIZLET: The introduction section of a research report should: Include a thorough historical review of the literature Define all of the terms that would be unintelligible to a reader with no previous exposure to the field Present the specific problem to be explored and described in the research strategy Be clearly labeled. What question should the introduction section of a research report attempt to answer? a. What are the theoretical implications of the current research? b. What is the point of the study? c. What is the logical link between the problem and the research strategy? d. All of the above are correct. e. Only a and c of the above are correct. Before you write, consider this: Why is this problem important? How does this study link to previous work? What are the primary/secondary hypotheses/objectives? What are their links to theory? How do the hypotheses and research design relate to each other? What are the theoretical and practical implications? Three parts to the Introduction Brief introduction, 1-2 paragraphs Review of relevant scholarship, 1-2 pages Purpose, rational, hypotheses, 1-2 paragraphs at the sections close. 10.4.3.1 The Brief Introduction A good introduction paragraph answers the following questions in 1-2 paragraphs What is the point of the study? How do the hypothesis and experimental design relate to the problem? What are the theoretical implications of the study and how does the study relate to previous work in the area? What are the theoretical propositions tested and how were they derived? In the middleabove ALL Demonstrate that the problem is IMPORTANT Narrative thread. Always refer to the THEORETICAL BACKGROUND Narrative thread. Closing paragraph a statement of purpose and rationale of project. Narrative thread. The closing paragraph(s) of the Introduction What variables did I plan to manipulate? What results did I expect and why did I expect them? (the logic of this should also be made clear) What is my rationale for each hypothesis? The lecture further reviews JARS elements. 10.4.3.2 Bikos Developmental Perspective on Learning to Write the Empirical Manuscript Over the years I have been learning writing skills of my own and, in my roles as instructor and peer reviewer, providing feedback to others. Below is an oversimplified model of what I think Im observing as students and scholars learn to write empirical manuscripts (in the specific APA style). Figure 1. The first stage of writing. Image of the first stage of writing Figure 2. The second stage of writing. Image of the second stage of writing Figure 3. The third stage of writing. Image of the third stage of writing Figure 4. The fourth stage of writing. Image of the fourth stage of writing 10.4.3.3 Perennial Notes from Research-Project Faculty Graders Start with your problem statement  What is your DV and why does the reader care? Theory must drive your model/manuscript.  A list of variables does not a theory-driven model make. Active headers are your friends  Not helpful: Gender &amp; RSB  More helpful: RSB vary across Genders 10.4.4 Method (APA 2.06; Chapter 3) Describes in detail how the study was conducted. Includes conceptual and operational definitions of variables. How much info is enough? Readers must be able to  Evaluate the appropriateness of the method  Judge the reliability and validity of your results  Replicate the study Many of the JARS elements have even more detail in the text that follows the table. In your first few papers, make sure to review and imitate. The lecture further reviews JARS elements. Regarding these tables  flowchart and tables in style manual, Appelbaum (2018) article, or website. 10.4.5 Results &amp; Discussion (Chapter 3) The lecture references the JARS elements in detail. Section 6.43 of the APA style manual details the basic form for statistical output (statistical strings); 6.44 provides statistical abbreviations and symbols. 10.4.6 Headings (APA 2.7) The 7th edition of the style manual updated the levels of headings. The change is to the L3 heading  making it a little easier for Word processing programs. There are now 5 levels of headings. A useful table that illustrates them can be found here. Headings follow a top-down progression. Each section (i.e., Title [on first page], Method, Results, Discussion) starts with an L2 heading. Do not include an Introduction heading  the first paragraphs of a paper are automatically expected to be introductory in nature. Heres the heading structure in the paper (a brief report) we are investigating: You Speak English Well! Asian Americans Reactions to an Exceptionalizing Stereotype Microaggressions Against Asian Americans (L1, centered, bold, title case) Method (L1, centered, bold, title case) Sample (L2, flush left, bold, title case) Procedure and Materials (L2, flush left, bold, title case) Analysis and Manipulation Check (L2, flush left, bold, title case) Results (L1, centered, bold, title case) Discussion (L1, centered, bold, title case) Conclusion (L1, centered, bold, title case) 10.4.7 Reference List The reference list should start on a new page with References in bold and centered (an L1 heading  like the title). The general format of the reference is: Author (Date). Title. Source. The 7th edition has made significant improvements in making this format consistent throughout the many types of references. Plus, Chapter 9 in the 7th edition has a number of tools for problematic reference entries. One substantial change in the 7th edition is the immediate use of et al. after the first authors name there are three or more authors. In contrast, up to 20 authors can be included in the entry in the reference list. Use a hanging indent and format this with the paragraph-formatting function of your word processors ruler. This means that the first line of each reference is flush left and subsequent lines are indented by 0.5 inches: The text-citations and reference lists must be 100% consistent. If you have consistently (and properly) used your reference management system, this will happen by magic. Even so, one of the last things I do is a text-ref/ref-list cross check. I open 2 copies of the manuscript and put them side-by-side on the monitor. Starting with the text (and in track changes), each time I come to a reference, I put an X in front of it on the ref list. I go through the entire document. If there are items in the ref list missing, I note it (then add it). If there are additional references in the ref list that I havent checked, I do a quick search to see if they are really missing, and if so, I delete them. For dissertation proposals and defenses, we ask first and second year students to do this for us  it familiarizes them with RVT topics, the dissertation process, and the literature. Because of Zotero, Mendeley, RefWorks, EndNote, and other reference management systems (as well as the good tools in the style manual), I wont say more about text-citations and reference lists. 10.4.8 Stylistic Issues (APA Chapter 4 on Writing Style and Grammar) APA (4.0) is committed to a literary style characterized by continuity (logical consistency of expression throughout a written work), flow (smooth cadence of words and sentences), conciseness (say only what you need to say), and clarity. I encourage the authors to read Chapter 4 of the style manual for examples of how to increase the effectiveness with which they write. Transitional words between sentences and phrases (or sentences) between paragraphs and sections assist with continuity and flow  Time: then, next, after, while, since  Cause-effect: therefore, consequently, as a result  Addition links: in addition, moreover, furthermore, similarly  Contrast links: but, conversely, nevertheless, however, although  Think twice about using adverbs (certainly, consequently, importantly, interestingly) as transition words. Active headings/subheadings contribute to continuity and flow. Dont add any more words than necessary. Say only what needs to be said:  No fluff (avoid: very, really)  Maintain a professional tone (avoid clichés, rhymes, alliteration, metaphors, slang  remember a global audience) Clarity is improved with a varied sentence length; long sentences can be confusing. APA style permits both active (subject, verb, object: students completed surveys) and passive (object of verb is presented first: surveys were completed by students) voice. The active voice contributes to direct, clear, and concise statements. More style-congruent advice: * Avoid abstract stacking. * Avoid organizing by an author(s) name(s).  Organize by ideas  Unless it is important, citations should be at the end of a sentence. Ask yourself why you are starting a sentence with an authors name  Is he or she the point of your sentence? Could be but most likely not. * Use quotations sparingly: short ones, infrequently. * Precision, continuity, clarity, efficiency (stop with the long sentences) * Active voice (It is banned as first word in paragraphs and sentences). * Manuscript must be written in first person.  Avoid this: Hypotheses for the present study included  Do this instead: In our study, we hypothesized * Past tense or present perfect tense for the literature review, method, and results sections; present tense for the discussion section. 10.4.9 Reducing Bias (APA Chapter 5) Chapter 5, Bias-Free Language Guidelines is new to the 7th edition. A big message is that this is-and-will-continue-to-be-evolving. Here are some of the highlights Describe relevant characteristics; it is likely unnecessary to collect and/or report on all personal characteristics for the topic being explored. Dont shy away/hide/gloss over actual differences in the target population from the general population. Describe them clearly and professionally. There are specific guidelines for level of specificity in labels/language for various topics (e.g., disability, age, gender identity, race/ethnicity/nationality, sexual orientation, SES). Look them up. A few guiding principles (but there are so many moreread the chapter):  Call people what they call themselves (especially in qualitative or participant-informed research designs). Also recognize that no group is monolithic so there may be within-group differences about this.  Accept that language changes with time  stay open minded.  There is debate about person-first language (a child with autism) and identity-first language (an autistic child). Get consultation and listen to the research participants.  White, cis-gendered, heterosexual, and U.S. is often the standard against which others are judged. This centers Whiteness. Avoid these false hierarchies. When these comparisons are made, placing the socially dominant group on the left side of a graph or at the top of a table may imply these groups are the universal standard. A (very) few specific details: * On identification of race:  African American is discouraged as an umbrella term for people of African ancestry worldwide because it obscures other ethnicities or national origins (e.g, Jamaica). In these cases use Black (with a capital B).  Caucasian is discouraged as an umbrella term for White or European because it originated as a way of classifying White people as a superior race. Use White (with a capital W).  Native American and Native North American seem to be preferred in North America.  Latin@ is now widely accepted for Latino and Latina; as is Latino/a. Latinx can also be used as a gender-neutral or nonbinary term inclusive of all genders. * Avoid writing about minorities. Terms like people of color or underrepresented groups are preferred. Do not assume that members of any of these groups are underprivileged. Terms like economically marginalized or economically exploited may be preferred. * Use sexual orientation not sexual preference, sexual identity, or sexual orientation identity. The term sexual and gender minorities refers to multiple sexual and/or gender minority groups or write about sexual orientation and gender diversity.  LGBT is considered outdated, but LGBTQ, LGBTQ+, LGBTQIA, AND LGBTQIA+ may be used to refer to multiple groups (but be careful and specific; if you are researching transgender peoplethen talk about transgender people). * They is now acceptable to use in the singular. There are a number of circumstances when this is recommended. A few include:  When it is the persons preferred pronoun.  When the pronoun is unknown.  In place of he or she, s/he, and (s)he. 10.4.10 Closing Thoughts Fluency in APA style is a long journey. One of my own strategies in an APA Cheat Sheet (presently 38 pages long). I wrote it to help with reviewing/editing/grading (and also for my own writing), so I can search on words/phrases that Im likely to say. I can add/update it. Each element in my cheatsheet has the section number (for papers I review as well as my own self-doubt when I wonder, later). Having now toured the 7th ed, what are your thoughts about its relation to power, privilege, racism/anti-racism, and White supremacy culture? Repeated are the characteristics of White supremacy culture. I have italized those that strike me as being reflected in APA Style. Perfectionism Perfectionistic culture Worship of the written word Only one right way Either/or thinking Concentration of power Power hoarding Paternalism Defensiveness Right to comfort Fear of open conflict Individualism Im the only one Progress is more/bigger Objectivity Quantity over quality Sense of urgency References "],["Zotero.html", "Chapter 11 Reference Management with Zotero 11.1 Navigating this Lessonette 11.2 Go Get It! 11.3 Your Library 11.4 Grabbing &amp; Storing Pubs 11.5 Inserting Citations 11.6 Creating the Reference List 11.7 Other Reasons I Love it So Much", " Chapter 11 Reference Management with Zotero Screencasted Lecture Link In the past  I discouraged the use of reference management programs (e.g., EndNote, RefWorks) because they often made mistakes and it was easy to spot papers where they had been used (because of the errors). I was introduced to Zotero when I sought to create a bibliography in Rmarkdown. Then I learned it could be used in Word. Even after submitting two articles for publication, I have yet to find it make an error(that is, when each reference has been correctly entered [only once] in Zotero). Thus  Im a fan. Count me in! This lecturette demonstrates the use of Zotero in the context of the APA style paper. I have a separate lecturette (in an .rmd file) for using Zotero in R. This quick introduction includes a Zotero demonstration for: acquiring references text references creating a reference list for use as your own personal library with the potential for collaboration admittedly, I have not yet tried collaboraiton (stay tuned) Reference management systems include resources like RefWorks, Endnote, Mendeley, and Citationsy. Microsoft Word even has its own process. 11.1 Navigating this Lessonette There is less than 30 minutes of lecture. If you work through the materials with me it would be plan for an additional hour. 11.1.1 Learning Objectives Learning objectives from this lesson include the following: Recognizing the ways that a reference management system will contribute to the efficiency (and quality) of a research project Saving references (including full text copies of publications) in the Zotero system Using Zotero to add citations in the text; and then create a reference list Organizing materials into your own library of resources 11.2 Go Get It! Zotero is available for Windows, Mac, and Linus. https://www.zotero.org/ Once you download it to your computer, you will also want to install the Connector  I use Firefox. 11.3 Your Library Never lose another pub! Zotero can become your library. Folders Attachments Full-text Snapshots with web addres Reference/bibliographic information is grabbed (Zoteros best guess) or each entry and can be updated if it is incorrect Image the Zotero library 11.4 Grabbing &amp; Storing Pubs Whether its through the library search engine, PsychInfo (or similar), or something you have found on a website, Zotero will grab either a snapshot of the website (so you can get back to it) or the full-text article and store it for you. To do this: Open Zotero This is even easier if, in Zoter, you have opened the file folder of the desired destination. If not, you can simply drag-and-drop entries into the desired folder(s). In your browser, user the Zotero Connector to navigate to t he closest you can get to full-text. Click the Zotero icon in your browser. Heading to Zotero, check to see what was cpatured. If the ull-text is missing, either try again (from a different place on the web), or Download the full-text and attach it separately by right-clicking on the entry and selecting add attachment. Double-check the info (in the far right column of your Zotero app) that was captured. Edit any errors (this will save you time later). Zotero captures ormal library items fairly well. It struggles more when you grab an item from a webpage. Sometimes Zotero cannot discern the Item Type. This can be problematic because it provides the wrong fields. You can change the item type by changing the selection in the top item in the bibliographic information. Screenshot of the process of saving a full-text document to a Zotero library Screenshot of the process of adding an attachment to an existing citation 11.5 Inserting Citations Zotero has a plug-in for Microsoft Word. When installed, a Zotero tab will be added to your toolbar. Screenshot of the first step in adding a text citation to a document in Microsoft Word To insert a citation, simply select, Add/Edit citation. Select the style you wish  APA 7th edition was available very shortly after the introduction of the 7th ed! You have a choice of single-spaced or double-spaced. Then simply type in any word on which you want Zotero to search your library (e.g., author name, partial title). Zotero will produce a list of items that match the criteria. Simply select it. Zotero will follow the 7th edition rules, shortening any citation that has 3 more authors to et al. for all citations. _ Zotero will automatically order citations alphabetically and/or by year of entry. AND, it will add the a, b, and c designations for identical pubs. If there are errors, simply return to the Zotero entry, fix it, and then Refresh (on the Zotero tab) and it should auto-correct. Screenshot of the second step in adding a text citation to a document in Microsoft Word 11.6 Creating the Reference List At the end of your document (or wherever you want it), return to the Zotero ribbon and select, Add/Edit Bibliography. Thats it. You just select it. 11.7 Other Reasons I Love it So Much I have moved from having folders of Reading Rooms everywhere. Now I have them all in one place. If I open the full-text from Zotero, it will open in my PDF reader/editor. I can use my PDF editing tools and everything is saved. Permanently. And I dont have to remember where I saved the document. It is possible to collaborate in Zotero. I can export the library to be imported by a collaborator and they should have all the things. Im not an expert in this and I think there is even more potential for this (but Im still learning). I can export the Zotero libraries as a BibTeX that can be used in my .rmd files where I can similarly do text citations and ref lists. "],["Tables.html", "Chapter 12 Table Magic 12.1 Navigating this Lessonette 12.2 Magic Happens When You", " Chapter 12 Table Magic Screencasted Lecture Link Fluency with the skills in this lecturette will be essential as you format tables for papers, journal articles, posters, and your dissertation. When you use formal table skills (in Word or Exceland the basics transfer well from one to the other), then the tables are less likely to corrupt and require reformatting when you transfer them from document to document. 12.1 Navigating this Lessonette There is about 30 minutes of lecture. If you work through the materials with me it would be plan for an additional hour. 12.1.1 Learning Objectives Learning objectives from this lesson include the following: Explore the tabs and commands in the table ribbons in word processing packages. Utilize basic table skills such as adding/deleting rows and borders and aligning cell content. Experiment with advancedtable skills such as splitting/merging cells and redistributing columns. Apply these skills to subsequent homework assignments and manuscript submissions. Screenshot of a complex table integrating CFA models and their corresponding output Screenshot of a complex table integrating numerous regression models In this lecturette, I will tour the basic skills, then replicate the above table from scratch. This table, thoughis pretty simple. We use a number of nested and stacked tables to represent our complex analyses. Screenshot of a table integrating thumbnail sketches and output for assessing univariate normalilty of three variables 12.2 Magic Happens When You Place individual elements into separate cells of a table (as opposed to tabs and spacing) tool holds them place. Item stems will word-wrap. Decimals are easy to manage. The table borders allow the author to identify formatting choices and make changes without impacting the remainder of the table (when relying on tabs and margins, existing formatting is not always obvious). 12.2.1 Starting the Table Start with the insert ribbon and the table icon. Either color in the row x column dimensions or click Insert Table to get a dialogue box where you can enter the number of columns and rows. Screenshot of the window allowing the user to specify the number of columns and rows in a table 12.2.2 A Few Handy Tools For borders and shading To obtain the borders/shading menu, right click on the table or select it from the table menu in the upper toolbar. Select none to make the table lines invisible. In some cases you may want to leave table lines (or some of the grid). Hint: I turn on (and leave on) ALL the borders until Im finishedthen selectively make them invisible. Screenshot of tools used to add shading to rows, columns, and cells For cell alignment, right click on the cells of interest. The Cell Alignment tool allows you to specify by cell(s), row(s), or column(s) how the text should align. Screenshot of tools available for specifying horizontal and vertical cell alignment Merging cells allows two or more cells to become one. This can occur vertically or horizontally. Drag across the cells you want to merge. Right click, then select Merge Cells. Screenshot of the Merge Cells option Need two cells separted? The split cells tools will subdivide a single cell into the desired rows and columns. Place your cursor into the desired cell. Right-click, then select Split Cells. Columns or rows out-of-whack? The Distribute Rows and Distribute Columns tools are incredibly powerful and can be used to even-out-the-space of either. Screenshot of the Distribute Rows and Distribute Columns tools Didnt quite plan right? Right-click in the cell to Insert or Delete rows, columns, or cells. Screenshot of the Insert and Delete tools Alternatively, if you just want to add a row, position your cursor just outside of the row immediately above where you want the row added and ENTER. 12.2.3 Decimal Magic Tabs (for alignment in columns) are in teh upper right, below the toolbars. Clicking through the tabs changes the option. Click until the decimal symbol appears. Once it shows, highlight the column (or row) for which you want to set a decimal place. If numbers dont automatically align, try backspacing or CTRL_TAB. Screenshot of the Decimal Tab 12.2.4 More Help from Table Properties The Table Properties window can offer advanced options or rows, columns, cells, and the table as a whole. Screenshot of the Table Properties dialogue box "],["Excel.html", "Chapter 13 Writing in Excel 13.1 Navigating this Lessonette 13.2 Where to Start 13.3 In Any Case, I Use Excel 13.4 Lets Tour 13.5 FAQs", " Chapter 13 Writing in Excel Screencasted Lecture Link In high school and college the method for writing term papers involved taking notes on index cards (note on front, citation on back), sorting them into sections of the paper, sorting each section into its proper order, and writing it up. Some years ago, I adapted that process to Excel. Getting some positive feedback or it, I wrote up a lecture on it. Even with improved reference management systems (like Excel) and R programs like papaja (for writing APA style manuscripts), I continue to use Excel for notetaking and organizing my thoughts. As you will see in this lesson, it also helps me separate the plaigarized material so that I do not unintentionally use it. Although the Excel spreadsheet is easy to create, the template I use in the lecture is in the Github book site. 13.1 Navigating this Lessonette There is about 35 minutes of lecture. If you work through the materials with me it would be plan for an additional hour. 13.1.1 Learning Objectives Learning objectives from this lesson include the following: Capture notes from primary source materials (along with the APA style citation) in Excel. Prevent plagiarism by clearly noting original material. Use the worksheets to organize sections of the paper. Use the sorting features of Excel to origanize the materials to facilitate easier writing. Use the Directory Merge tools to dump the written paper into Microsoft Word. 13.2 Where to Start 13.2.1 Bottom Up Starting from the bottom up means identifying the primary variables in my study and begin researching each of them. I start bottom up when: I know the general topics that I want to investigate, but I dont know the literature well (or as well as Id like), and I need to develop a strong narrative thread For example, if I know I want to explore the relations between the following variables, I will begin with a bottom up approach, Archiving information about each construct Documenting the ways that the variables relate to each other Screenshot of bubbles representing the three variables: vocational identity, psychological well-being, and calling 13.2.2 Top Down Starting from the top down occurs when I know the precise model I want to investigate and the relations Im predicting. I will frequently draw the model so that I can keep it in front of me as I am researching and writing For example, if I am going to write a research proposal testing the following model, I will likely begin with top down approach. Screenshot of a moderated mediation involving the variables search and presence of calling, vocational identity, and psychological well-being After the introductory paragraph(s), my paper will focus on the importance of the DV, psychological wellbeing. Building backwards, I would then talk about the relationship between vocational identity and psychological well-being. Vocational identity contributes to psychological well-being in college students The effects of calling on these variables are not well understood -Positive effects have been documented There may be a dark side to calling  for those who seek and do not find Therefore, the purpose of our study is to investigate the mediating role of vocational identity on the relation between search for calling and psychological well-being. Within this model, we propose that presence of calling moderates the relation between search for calling, such that, those who search for calling and find it, have stronger vocational identity, and, in turn, higher psychological well-being. And, those who search for calling but do not find it, have lower vocational identity, and lower psychological well-being. 13.2.3 Mostly I Start in the Middle That is, I often know that the variables I\"m interested in relate to each other, but I want to use the literature to further solidify the paths I will specify in my research mode. Screenshot of a moderated mediation involving the variables search and presence of calling, vocational identity, and psychological well-being 13.3 In Any Case, I Use Excel I use Excel to organize my notes: In empirical papers for introduction and discussion (not method or results) For qualitative results For book chapters, literature review, theoretical papers There are numerous benefits to this approach. I believe that it: Facilitates group writing Creates an archive/cannon/library of our most used resources Clearly identifies plagiarized material and allows us to understand how/where we have integrated and adapted the material Makes tracking primary and secondary references so much easier Easy to order/re-order through revisions The process of writing in Excel includes: Note-taking from primary sources to include  Direct copy plagiarized material from the source  Taking notes on why we wanted it  Proper reference documentation at first use Iteratively working on the outline Refining categories/sections/headings Ordering the notes Writing the first drafts of the ms DIRECTLY into excel *Transferring to the word processing software 13.3.1 The Structure of my Spreadsheet Below is a screenshot of how I set up the worksheets in my spreadsheet. Screenshot of the tabs of my Excel worksheets Instructions Co-authors leave each other notes on the game-plan Outline Developing the outline is iterative/dynamic and, especially when beginning from bottom up or somewhere in the middle, is updated and revised frequently Screenshot of the structure of my Outline worksheet Tabs for each Section Correspond with outline numbers Contain the following columns  Order  Categories  Writing for ms  Plagiarized copy  Notes  First cite  Subsequent cites  Full citation  Page(s)  By References Near the end of the project, assemble a full reference list 13.4 Lets Tour The first tour is quick and hypothetical. In it, I transer the written document from Excel to Word (this is the supplement reerred to in the screencast). Open up a new/blank word document (one for each worksheet of material). Click on the Mailings tab and select Start Mail Merge and (optionally) Step by step mail merge wizard Select Directory THIS IS THE MOST CRITICAL STEP Select Recipients. Use Browse to locate the spreadsheet (if the spreadsheet is on a SP [or other cloud] folder and you cant select it from a networked drive, you may first need to download it to your computer). In Word, select the worksheet whose data you want to import. It should be sorted properly (first). Click Edit Recipient List. You may wish to turn off the 999s. Select Insert Merge Field. I chose, Writing for ms. I added 2 spaces after the element. Select Finish &amp; Merge. Edit individual documents All The text will be organized as one big paragraph, will likely need formatting updates, and may have spelling errors (that you didnt make.). At present, I only know how to merge 1 worksheet at a time into separate documents (then those should be copied together). Screenshot from the Directory Merge process The second tour includes a series of screencasts that are authentically a new project from the very first step. The RVT (and I, separately) have several projects coming that involved calling/vocation. Ive dabbled in the calling literature, but dont know it thoroughly. Im using the spreadsheets to begin to Capture the info Organize it in my head (and in excel worksheets) And then craft it into arguments for a handful of empirical manuscripts These screencasts will document that process from start, to, I hope a published manuscript (or at least one thats submitted. Ideas included Starting with the empty excel spreadsheet Assuming no knowledge (or very little) of the literature, therefore  Categories are broad and non-directional; just capturing info  A priori, I can guess I want categories of: definitions, outcomes, measures, norms These wont all make it into papers; Im just getting my footing Reviewing the literature/marking-it-up before notetaking Research team members often keep common Reading Room folders in the cloud As soon as I get my footing, I can assign some of these articles to team members who can also collect the data into the spreadsheets. **8 months, 1 presentation, 2 white papers, and 1 journal article later What worked well: One core spreadsheet gave was the source for 4 projects We learned to save as a copy of the original raw notes because those gross groupings were a fantastic well for substantial revisions and related projects When we received editorial feedback and I thought it would be a quick revision, I still found it easier to return to the spreadsheets, supplement-and-reorder my notes, write in excel and transfer back into word. What didnt go as well: Likely because of the deadlines, the substantial requests for revision, and a full year, I didnt use the team as much as I would have liked We didnt follow all the rules Didnt capture a lot of page #s Didnt have detailed outlines (or update outlines with revisions) Would I do it again? Some years later  yes, I still write in Excel (even with the presence of other tools like Zotero). 13.5 FAQs (For students in our doctoral program) Am I required to Write in Excel for my mentored research project (MRP)?  YES, if you are in the Bikos RVT.  NO, if you are anyone else. Whats the difference between Editing in Excel Online and Editing in Full Excel.  Excel ONLINE allows multiple editors at once, BUT You have to be working on different worksheets You dont have some of the full benefits of excel (I find it difficult to sort and so some other functions that I really like)) You dont need to hit SAVE. Everything you type is automatically saved. So be careful, weve unintentionally deleted stuff and didnt realize it. OUCH. Using the full EXCEL package gives you full EXCEL functionality, there are nuances: If one person is working in full excel, it locks everyone out from everything except viewing. That is, no one else can work IN ANY CAPACITY on the document at the same time. It looks like youve downloaded it, but you have not. When you hit SAVE, it saves back to SP. If you intentionally or unintentionally disconnect from Internet, it updates once you are reconnected. You must hit SAVE in order for your changes to be saved. I prefer to work in full Excel and its only rarely a problem that teammates have my same schedule and want to work at the same time. When they do, we just coordinate. "],["references.html", "Chapter 14 References", " Chapter 14 References "]]
